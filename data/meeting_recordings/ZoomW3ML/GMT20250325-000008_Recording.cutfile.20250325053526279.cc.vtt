WEBVTT

1
00:00:01.985 --> 00:00:04.985
I know Mary has some special announcements to make.


2
00:00:04.985 --> 00:00:08.985
I think I already did. Oh, wait, wait, wait. I didn't. I didn't.


3
00:00:08.985 --> 00:00:21.985
So let's see. We just wanted to like say that from today will be a nice idea to highlight a builder of the week or something.


4
00:00:21.985 --> 00:00:35.985
We can do it randomly. So it's not going to be like, at least that's what I thought. Hi, let me know if you have other ideas. But we're just going to randomly highlight a person that had probably struggled in the beginning and had struggled in the beginning


5
00:00:35.985 --> 00:00:40.985
Right now is doing much better and I feel like it's a great example for others too to get inspired.


6
00:00:40.985 --> 00:00:48.985
And for this week for this week Hi, who are we highlighting for this week?


7
00:00:48.985 --> 00:00:54.985
So this is supposed to be very special because we've been watching you guys for a couple of weeks.


8
00:00:54.985 --> 00:00:59.985
When I say a couple of weeks, I think what I meant is what Three weeks?


9
00:00:59.985 --> 00:01:00.985
Right? It's been three weeks, right? Okay, two weeks.


10
00:01:00.985 --> 00:01:05.985
Two weeks. It's been two weeks.


11
00:01:05.985 --> 00:01:10.985
Everyone's going through a different journey, right? Some people hit the ground running really fast.


12
00:01:10.985 --> 00:01:18.985
Others took their time to think about what they wanted to build And a lot of you guys run into things that you've never seen before.


13
00:01:18.985 --> 00:01:23.985
And for the first time in your life you have to debug stuff built by AI.


14
00:01:23.985 --> 00:01:42.985
And I don't know how you feel about that, but I think from our perspectives, it's very inspirational to see somebody going from zero to like a hundred Just vibe coding and then finding their way out of bugs So we want to dedicate once a week we want to dedicate like


15
00:01:42.985 --> 00:01:50.985
An announcement to announce some of our students who we think are we think such an inspiration for everyone here.


16
00:01:50.985 --> 00:01:55.985
So, um. We have a list and Mary's going to say it.


17
00:01:55.985 --> 00:02:03.985
We said you had a list. Or you're picking one person.


18
00:02:03.985 --> 00:02:05.985
I said, you have a list.


19
00:02:05.985 --> 00:02:10.985
I do just because it was so hard to pick one person and I feel like that would be unfair for everybody else.


20
00:02:10.985 --> 00:02:22.985
But like from the top of my head, I just wanted to let you know that some people are also reaching out to me in the DMs as well, not just in the general chat, especially those who are like confused or scared or just overwhelmed.


21
00:02:22.985 --> 00:02:23.985
Scared. What did I do? Just kidding.


22
00:02:23.985 --> 00:02:42.985
And what You didn't do enough thing. You're doing great. No, but for those that were so I just wanted to first of all say like Pravina, I just want to give a shout out to Pravena because We had a conversation before and


23
00:02:42.985 --> 00:02:53.985
I could resonate with like the feelings of overwhelm and I feel like the first few weeks were really tough for many of us because we basically put you in the middle of the fire and said, you got to figure out.


24
00:02:53.985 --> 00:03:07.985
And I'm just like so proud for those who have never coded before and stuck with us with us for like two weeks now and I just want to congratulate Praveena for doing great.


25
00:03:07.985 --> 00:03:28.985
And setting up the login page, even though it was hard to figure out And I have another second person that I think is worth highlighting hi Feel free to like add more people too. But these are just like from the top of my head. Everyone, it doesn't mean that everybody else is not doing great. In fact, there are so many amazing people, but I know that you guys are already doing great.


26
00:03:28.985 --> 00:03:36.985
I mean, you're already like an A-list, but I'm talking about people who have been struggling a little bit and I just want to give a shout out to those people.


27
00:03:36.985 --> 00:03:42.985
And second person I had in mind was Kelsey. I just think that you're doing amazing, Kelsey.


28
00:03:42.985 --> 00:03:49.985
You did a great, like, I know you were struggling with your data set and then you said, wait a minute, let me regroup.


29
00:03:49.985 --> 00:03:56.985
Let me see what's important. And then you completed the thing and you even put on the demo. So I think that was awesome.


30
00:03:56.985 --> 00:04:10.985
So we'd love to highlight more people, more like stories like these. So feel free to share like your struggles or whatever you're feeling in the DM or even general chat because later on You're going to overcome them and we're going to celebrate you.


31
00:04:10.985 --> 00:04:16.985
So I just want to like say congratulations guys let's let's keep building


32
00:04:16.985 --> 00:04:20.985
Thank you, Mary. That's very kind of you. Thank you.


33
00:04:20.985 --> 00:04:22.985
Great job, Pravena. Yeah.


34
00:04:22.985 --> 00:04:25.985
Yeah, thank you so much. Appreciate the kind words.


35
00:04:25.985 --> 00:04:31.985
Awesome. Happy to hear this. Great.


36
00:04:31.985 --> 00:04:37.985
I think that's all I wanted to say. Hi. Unless you had more people to highlight.


37
00:04:37.985 --> 00:04:44.985
No, I don't. But today we're going to try a new drawing tool called Thick Jam.


38
00:04:44.985 --> 00:04:50.985
Does anyone here know what Fig Jam is?


39
00:04:50.985 --> 00:04:51.985
Nobody. Okay.


40
00:04:51.985 --> 00:04:56.985
This is similar to Figma because I've heard of figma


41
00:04:56.985 --> 00:05:02.985
Yeah, it is a tool from Figma. Anyone here knows what Figma is?


42
00:05:02.985 --> 00:05:03.985
Yep.


43
00:05:03.985 --> 00:05:04.985
Yeah.


44
00:05:04.985 --> 00:05:10.985
Anyone here had, okay, I see some nods So Figma, let me just share my screen real quick


45
00:05:10.985 --> 00:05:32.985
What a great segue. So Figma is a uh design tool. It's a tool for designers to create mock-ups and stuff like that for mock-ups you know to working in a development team so designer can work with developers and now you can even make a design and then export it as code.


46
00:05:32.985 --> 00:05:40.985
Which is really cool. Side fun fact, my sister works at figma So I'm supposed to be like.


47
00:05:40.985 --> 00:05:47.985
The cool techie little brother but then my sister has more interesting job.


48
00:05:47.985 --> 00:05:59.985
It's like a rivalry that never ends, unfortunately. But I'm going to send out this link for you guys so that we can all hop on this big jam together.


49
00:05:59.985 --> 00:06:05.985
So let me jot this in the chat real quick.


50
00:06:05.985 --> 00:06:06.985
Okay. Oh, yeah.


51
00:06:06.985 --> 00:06:13.985
Is it going to have space for all of us?


52
00:06:13.985 --> 00:06:20.985
Okay, I'm seeing orange so fast. I'm going to just drop this thing in.


53
00:06:20.985 --> 00:06:23.985
Hello, everybody. When I was at my last job.


54
00:06:23.985 --> 00:06:33.985
Whenever we're on like a fig jam with like 20 or 30 people or so You have to pay really close attention so that your cursor doesn't touch someone else's cursor without their consent.


55
00:06:33.985 --> 00:06:39.985
Otherwise, everyone gets into trouble.


56
00:06:39.985 --> 00:06:53.985
Okay, everybody. Today, we're going to be talking about arguably one of the most important foundation towards understanding agents.


57
00:06:53.985 --> 00:07:01.985
There's a couple of topics we're going to talk about. One of them is tool calling and the other one is structured outputs.


58
00:07:01.985 --> 00:07:08.985
So let me just write that out here real quick. One is tool calling.


59
00:07:08.985 --> 00:07:19.985
And then I like how everyone just all of a sudden just stops when I start typing. The other one is structured.


60
00:07:19.985 --> 00:07:27.985
Outputs. Okay, so I have a question for everyone here.


61
00:07:27.985 --> 00:07:35.985
Oh, there's a table. Hold on. Hold on. There we go. That's way better.


62
00:07:35.985 --> 00:07:40.985
We have an upgrade, guys. This is not… free excali draw.


63
00:07:40.985 --> 00:07:59.985
Silliness. Multi-billion dollar multi-billion company's tool okay so tool culling and structure outputs. I'm sure for some of you guys, these are familiar terms so Does anyone want to take a jab at explaining what tool cooling is.


64
00:07:59.985 --> 00:08:00.985
On the call?


65
00:08:00.985 --> 00:08:18.985
It's a tool call is to my understanding is like a plugin to the LLM to do the work that by default llm may not be able to do it. Structured output would be something to have a standard response structure so that you can parse it like a JSON or something.


66
00:08:18.985 --> 00:08:23.985
So that you can parse the output and do the next steps.


67
00:08:23.985 --> 00:08:36.985
Okay. I'm just going to correct that first part that you said there real quick So for tool calling What it means is that it's a large sandwich model plus an application.


68
00:08:36.985 --> 00:08:54.985
So the large language model is taking in an input And it's basically fine-tuned or pre-trained in a way so that If the input has a list of tools on the output, it will output the tool that is the most relevant for the conversation.


69
00:08:54.985 --> 00:09:09.985
That's basically it. So for example, I say to an LLM that, hey, you are an expert at a couple of different things. You have access to a tool that get you the weather. You have access to a tool that get you the stock price.


70
00:09:09.985 --> 00:09:22.985
And the next message I have for it is What is the current… the stock price for Tesla, I know it's going to go, it's been going down for a while. So I'm like, what's the stock price for Tesla?


71
00:09:22.985 --> 00:09:43.985
Large language models nowadays is smart enough to know that, hey, I'm asking for a particular tool and it's supposed to choose a tool as long as I put that little prompt in my system message that says, you are an expert at choosing tool or you have access to these tools and you only output the tool.


72
00:09:43.985 --> 00:09:55.985
So like you only… realistically, you only have to worry about prompting it to use tools If you're using an open source model.


73
00:09:55.985 --> 00:10:06.985
If you're using a model that is like kind of have no infrastructure around it. So kind of like a llama 3.3 that is you setting up from scratch.


74
00:10:06.985 --> 00:10:16.985
But if you're hitting like OpenAI, if you're hitting like any frontier models right now like cohere or anthropic.


75
00:10:16.985 --> 00:10:21.985
You usually have a parameter that allows you to turn on this thing called tool calling.


76
00:10:21.985 --> 00:10:27.985
And then you're passing a list of tools and then it will do that for you. And Sarga was right that for tool calling.


77
00:10:27.985 --> 00:10:31.985
Do you now move from an LLM doing just, you know.


78
00:10:31.985 --> 00:10:37.985
Text generation to now LM deciding what code to run or what functions to run.


79
00:10:37.985 --> 00:10:46.985
So that's basically it. So does anyone want to like… took a jab at recapping what I just said.


80
00:10:46.985 --> 00:10:51.985
Just to see if you like… understood what tool calling is.


81
00:10:51.985 --> 00:10:56.985
And you can say it wrong. I don't care. I'll tell you.


82
00:10:56.985 --> 00:10:57.985
There's nothing wrong with that. Yeah.


83
00:10:57.985 --> 00:11:07.985
Sure. Sure. So utilizing external APIs and other tools with an LLM to call on them is my Getting that correct?


84
00:11:07.985 --> 00:11:29.985
Yeah, that's pretty much it. And not, you know, not constrained to just third-party APIs. These are literally just like code function. So like when you write like, you know, a function in JavaScript Like that's one of the use cases. So go ahead and write that under tool calling, like the definition that you just said.


85
00:11:29.985 --> 00:11:32.985
Ooh, we got to write things.


86
00:11:32.985 --> 00:11:41.985
Yeah, I'm like getting lazier and lazier every week so Starting today, I'm not writing the tables. Next week, I'll let somebody else do the presentation.


87
00:11:41.985 --> 00:11:45.985
Oh, my God. I don't think there's permission though to write


88
00:11:45.985 --> 00:11:52.985
Okay. Approve. Let's see. Oh, hmm.


89
00:11:52.985 --> 00:12:05.985
Was this in, let's see if this… Okay, can you guys write now?


90
00:12:05.985 --> 00:12:07.985
Let's see.


91
00:12:07.985 --> 00:12:11.985
Nope, it won't work.


92
00:12:11.985 --> 00:12:16.985
So anticlimactic. Hold on. Can view, can edit, can edit.


93
00:12:16.985 --> 00:12:21.985
Yeah, double click inside and start typing. I was able to.


94
00:12:21.985 --> 00:12:28.985
Edit. Okay, can you guys edit now?


95
00:12:28.985 --> 00:12:31.985
Yeah, you're right.


96
00:12:31.985 --> 00:12:48.985
All right. I think autumn, it's Autumn's turn.


97
00:12:48.985 --> 00:12:56.985
I think we need to do there's on the panel in the bottom it says view only. You need to ask to edit and then it automatically approves you.


98
00:12:56.985 --> 00:13:01.985
That's what happened to me.


99
00:13:01.985 --> 00:13:05.985
I think I made it so anyone can edit now. Maybe you need to refresh or something.


100
00:13:05.985 --> 00:13:11.985
Yeah, refresh.


101
00:13:11.985 --> 00:13:15.985
Ooh, somebody's typing something.


102
00:13:15.985 --> 00:13:17.985
Dwayne, that's not your turn. It's on.


103
00:13:17.985 --> 00:13:21.985
It's working now. Okay, hang on.


104
00:13:21.985 --> 00:13:23.985
Dwayne didn't type anything.


105
00:13:23.985 --> 00:13:29.985
Oh.


106
00:13:29.985 --> 00:13:37.985
Dwayne's like, not me.


107
00:13:37.985 --> 00:13:41.985
I'm trying to think of another word other than just tools.


108
00:13:41.985 --> 00:13:49.985
There we go. Thank you.


109
00:13:49.985 --> 00:13:57.985
Yeah, so it could be external functions, internal functions, like internal in terms of like inside of your application.


110
00:13:57.985 --> 00:14:04.985
Yeah, so while we're doing that, let me pull up the AI SDK.


111
00:14:04.985 --> 00:14:16.985
And I'll show you guys what how you can do that in how you can do that In here so in here You can go into the documentation, you can look up tool calling.


112
00:14:16.985 --> 00:14:32.985
Let's see. Tool calling. Yeah. So this right here Tools are objects that can be called by the model to perform a specific task. Aisdk core contains three elements, description, parameters, execute.


113
00:14:32.985 --> 00:14:39.985
Okay, so now that we know that when you give a list of tools to a large language model and tell it that, hey, you can use these tools.


114
00:14:39.985 --> 00:14:47.985
It will return back the tool name. Not only that, it can also return back the parameters or the arguments that can go inside of the function.


115
00:14:47.985 --> 00:15:00.985
So for example, I have like get weather function And inside of the get weather function, I have like an argument for like city name The large language model is smart enough to look at my query and be like, hey, okay, this person is asking about like.


116
00:15:00.985 --> 00:15:09.985
San Francisco. So I'm going to extract that and then throw that into the tool call and then run the tool with the new parameter.


117
00:15:09.985 --> 00:15:14.985
So let's take a look at the… the sample code here.


118
00:15:14.985 --> 00:15:27.985
So here, if you're using Next.js and TypeScript. And you're using AI SDK, what you'll see is you can Basically, you use the same method as when you were generating regular text.


119
00:15:27.985 --> 00:15:40.985
It still generate text and then you pass in like your GPT-4-0 whatever But then you have this like property that you can pass in. This property called tools. And then in here, what you can do is you can pass in like, you know.


120
00:15:40.985 --> 00:15:48.985
Different tools. So the way you do that is you create a property name And then the property value.


121
00:15:48.985 --> 00:15:53.985
So it could be weather, it could be like stock, it could be whatever As long as you don't have like a space between.


122
00:15:53.985 --> 00:15:59.985
And then you use this thing called tool, which you import from the AI SDK.


123
00:15:59.985 --> 00:16:09.985
To define the actual tool that the AI can use. And this is really funny because This is basically giving it to the large language model, which means that the tool name actually matters.


124
00:16:09.985 --> 00:16:19.985
So you just want the tool to do like get information from Tavili or get information from web Or maybe the tool is called web search.


125
00:16:19.985 --> 00:16:22.985
Then you need to call it the web search. You can't just call it like XYZ.


126
00:16:22.985 --> 00:16:35.985
Because that affects the decision-making process from the ALM. And as your application gets a little bit more complex, what you really want to do is not only have a good name for your tool, but also have a good description.


127
00:16:35.985 --> 00:16:56.985
The description tells the LLM when to use it. And feel free to, in the description, give it examples of when to use it. So for example, let's say a tool, your application has a tool for the LLM to Do web search, tell it when to use it. So tell it like, okay, so if you're looking at the messages history, you're looking at


128
00:16:56.985 --> 00:17:02.985
The retrieval and you don't see enough information to answer the user's question.


129
00:17:02.985 --> 00:17:11.985
You must use a web search tool so that in that case, it'll trigger the web search tool when the situation calls for it.


130
00:17:11.985 --> 00:17:19.985
Yeah, and then… There are two ways to, like this goes for both Python people and Next.js people.


131
00:17:19.985 --> 00:17:25.985
There are two ways to do what you would do with the Catool after it's been chosen.


132
00:17:25.985 --> 00:17:40.985
You could either… choose like you either just look at the result as it is because right now what happens is it's going to like just give you like the weather tool as like, hey, based on our conversation, I have chosen this tool


133
00:17:40.985 --> 00:17:47.985
But using a wrapper SD like library like the AI SDK allows you to execute the tool as well.


134
00:17:47.985 --> 00:17:57.985
So before you had to like parse it and say, okay, so because it chose web search, I have to run this function But here you have a callback.


135
00:17:57.985 --> 00:18:04.985
That you can pass in here. So let's say your web search tool is Tavilly. This is where you pass in the Tavili function.


136
00:18:04.985 --> 00:18:12.985
And then it'll get executed on the front end or the back end, depending on like what kind of application you're building.


137
00:18:12.985 --> 00:18:24.985
And… Yeah. And then it gets more complicated than that. So, so far… Do any of these things make sense to you guys on like a high level?


138
00:18:24.985 --> 00:18:28.985
In terms of tool calling. If you have questions, just ask me right now.


139
00:18:28.985 --> 00:18:40.985
So generally, in the prompt itself we specify right like if you want to use this, if you want to fetch weather, then use this tool or something like that.


140
00:18:40.985 --> 00:18:41.985
Yeah. Yeah, you should absolutely do that. You should absolutely do that.


141
00:18:41.985 --> 00:18:46.985
Is that not the case here?


142
00:18:46.985 --> 00:18:53.985
In multiple places than speaking from experience. So you have the system message.


143
00:18:53.985 --> 00:18:56.985
That's why you should say it. You should say that you have access to these.


144
00:18:56.985 --> 00:18:58.985
Five, 10 different tools. Each one does X, Y, Z.


145
00:18:58.985 --> 00:19:00.985
Okay.


146
00:19:00.985 --> 00:19:15.985
And then you specify again in the description. And then you specify again in the parameters. So the parameters would be like k if XYZ is available, then you got to insert that. So the parameter goes inside of the function, right? Like function has arguments.


147
00:19:15.985 --> 00:19:22.985
Those are just parameters. Yeah, so you have to specify a couple of different places.


148
00:19:22.985 --> 00:19:25.985
So the system message and then the description of the tool.


149
00:19:25.985 --> 00:19:30.985
And then in the description of the tool, feel free to give it examples.


150
00:19:30.985 --> 00:19:40.985
Colloquially, we call this a few shot, even though it's not technically fine tuning on pre-training. A few shots just mean like, you know, you give it, you give the model, like.


151
00:19:40.985 --> 00:19:49.985
A couple of different examples so that it knows how to when to do something better.


152
00:19:49.985 --> 00:19:51.985
How does that sound, Segar?


153
00:19:51.985 --> 00:20:02.985
Yep. Yep. I was also wondering, is this the like similar to AI SDK is this provision also available through any other frameworks Or like OpenAI's SDK itself, can we do that as well?


154
00:20:02.985 --> 00:20:08.985
Yeah.


155
00:20:08.985 --> 00:20:13.985
Yeah, so it gets a little bit more complicated than that. And I'll explain right here.


156
00:20:13.985 --> 00:20:20.985
Everybody gather around. I'm going to explain this. Okay, we got the LLM.


157
00:20:20.985 --> 00:20:27.985
Tool calling is an LLM thing The infrastructure around it, like the AI SDK, is just the software engineering stuff around it.


158
00:20:27.985 --> 00:20:35.985
To make your life easier. So the LLM should be… fine tune.


159
00:20:35.985 --> 00:20:47.985
Hold on. New tool. How do I, what's the best way to do this actually Let's see.


160
00:20:47.985 --> 00:20:52.985
I know I have sticky notes in here. Let me try to find… Oh, there they are. Sneaky.


161
00:20:52.985 --> 00:20:57.985
Boom, there you go. Okay, we got LMs.


162
00:20:57.985 --> 00:21:05.985
So has to be fine tuned to use tools otherwise low performance.


163
00:21:05.985 --> 00:21:18.985
And we see this from models like GPT-3. So GPT-3 was able to use tools, quote unquote, but it was terrible at it like you have to tell it like 20 times when to use what in order for it to


164
00:21:18.985 --> 00:21:28.985
Be able to pick the right tool. Later stage models, like starting with gpt4 And this is actually a reason why GPT-4 kind of kickstart the whole agent stuff.


165
00:21:28.985 --> 00:21:44.985
Back in 2023 like before GPT-4 like it's just really hard to build agents um GPT-4 was sort of… fine-tuned to be able to use tools When given the opportunity to use tools.


166
00:21:44.985 --> 00:21:51.985
And it was able to pick tools based on the situation of the conversation, very situationally.


167
00:21:51.985 --> 00:22:01.985
So this is a very LLM thing. We haven't talked about the software part yet And this is not AI SDK, not Light LLM, not anything like that.


168
00:22:01.985 --> 00:22:11.985
If you have an LLM and if you just run it on your computer and you tell it like, oh, I… There are tools you can use. It can do this as long as you prompt it really well.


169
00:22:11.985 --> 00:22:23.985
And that's why… SDKs or libraries like Libraries like Langchain AI SDK.


170
00:22:23.985 --> 00:22:32.985
I don't know if ALM does this, but I know Pydantic ai or you know open ai agents, SDK.


171
00:22:32.985 --> 00:22:37.985
They all have… built-in problems.


172
00:22:37.985 --> 00:22:55.985
Built-in problems for tool use. The reason for that, this is because If you were to go and try to prompt a model to use tool today, you're not going to get that great of an experience compared to somebody who has been doing this for a while.


173
00:22:55.985 --> 00:22:59.985
And this is the same reason why libraries like Langchain was created.


174
00:22:59.985 --> 00:23:11.985
Which is because there are patterns that have been repeated over and over. So people just kind of build a library around it and then Now you just have this pattern that you can just plug in. So whenever you declare a tool in Langchain.


175
00:23:11.985 --> 00:23:17.985
There's a whole set of problems behind that that says. You are and blah, blah, blah. You can use this tool and blah, blah, blah, blah, blah.


176
00:23:17.985 --> 00:23:23.985
But you had to click through a bunch of stuff to see it because it's in the library's code. It's not visible to you.


177
00:23:23.985 --> 00:23:39.985
All you see as a user of Langchain or as a user of AI SDK All you see is that, oh, I can just… put like a little like tool thing here and it'll just work but There's like a whole bunch of like hidden prompts behind it.


178
00:23:39.985 --> 00:23:51.985
And this is all like prompting stuff. You'll see like, you know, if you pass in a super small model, it'll do terribly and you pass in a modern and recent model like GPT-4-0, it will do really well.


179
00:23:51.985 --> 00:24:05.985
Because it's the same prompts behind the scenes, but then is the model smart enough to even use tool, that kind of stuff so If you end up using like any of the frontier models today and you use like a library like


180
00:24:05.985 --> 00:24:26.985
The ISDK or light LLM or lang chain you'll likely you'll have like… like the probably the most consistent experience with using tools, you'll be fine basically Unless you're trying to push the boundaries and like give it like a bunch of tools or your use case is like kind of niche then you might need to like


181
00:24:26.985 --> 00:24:43.985
Optimize stuff here and there but Yeah, so that's the behind the scenes. So you need an LLM that knows how to call tools, you need a set of infrastructure, software infrastructure around it so that it can like create tools and in a clean code way and then like


182
00:24:43.985 --> 00:24:57.985
Potentially be able to execute it in a clean way That's why we use these SDKs so that you know this could have been like not 20 five times more amount of code if you don't use like a library like this to set up these tool calling stuff.


183
00:24:57.985 --> 00:25:04.985
Yes, I hope that makes sense why, you know. S-a-i-s-d-k and stuff like that.


184
00:25:04.985 --> 00:25:09.985
Exists and why they work with tool coding and all these things.


185
00:25:09.985 --> 00:25:19.985
Hi. By any chance, do you know of any open source models that work like at least semi well with tools?


186
00:25:19.985 --> 00:25:36.985
Yeah. Yeah, Quan models do really well. I know Deep Seat does decently as well Anything that's came out recently, they all have like tool calling baked in Because this is like, like I said in the beginning, this is the foundation of


187
00:25:36.985 --> 00:25:45.985
Knowing how to run agents. The reason why Asians is super useful is because they can interact with applications and third-party external APIs, right?


188
00:25:45.985 --> 00:25:52.985
All through tool calling. But I want to like introduce you guys to this thing as well.


189
00:25:52.985 --> 00:26:01.985
Small agent. So there are two school thoughts to this, right? There's a school of thought that says, hey, if we just lay out all the tools.


190
00:26:01.985 --> 00:26:06.985
And if you think about MCP, MCP is basically tool calling, by the way.


191
00:26:06.985 --> 00:26:13.985
There's a server that has a bunch of tools. And the description of when to use these tools. And then your agent is kind of like, oh, I'm reading all these descriptions.


192
00:26:13.985 --> 00:26:20.985
And I have this task I need to do. I'll just call the tool that I need. That's what this whole MCP thing is about.


193
00:26:20.985 --> 00:26:26.985
Tools and then your agent goes to the tools and like, I'll read all this and I'll run the thing that I need.


194
00:26:26.985 --> 00:26:31.985
But there's two school thoughts. Let's going back to fig jam here.


195
00:26:31.985 --> 00:26:39.985
The tool school thoughts, you either do um tool calling.


196
00:26:39.985 --> 00:26:48.985
Let's see. You either do tool calling Or you do… Code generation.


197
00:26:48.985 --> 00:27:09.985
So there are a couple of papers that came out Not recently. There are some that came out recently but argues that you get better performance when running like like the end goal the end goal End goal is… uh to


198
00:27:09.985 --> 00:27:23.985
To run a process of some kind, maybe like call external API or external you know change a front end thing.


199
00:27:23.985 --> 00:27:38.985
That kind of stuff. So either of these would help you accomplish that. But the more beginner friendly stuff is tool calling And some people argue that, hey, like, you know, if you allow the model to generate code.


200
00:27:38.985 --> 00:27:50.985
Based on the specs. So the specs is just like, you know, the description of like the tool and stuff like that you get better performance. So like instead of writing like, hey, you have access to get weather and get stocks


201
00:27:50.985 --> 00:27:55.985
They let the model write out what get stocks is in Python.


202
00:27:55.985 --> 00:28:03.985
Or they'll let the model write out like get weather in python And then they argued that because there's more flexibility there.


203
00:28:03.985 --> 00:28:06.985
The model can write the right function to call the right endpoint.


204
00:28:06.985 --> 00:28:12.985
Instead of like being you know constrained in a function that you wrote for the model.


205
00:28:12.985 --> 00:28:16.985
But you don't have to worry about this right now. Just know that there are two school thoughts out there.


206
00:28:16.985 --> 00:28:24.985
One has let the model write code in a sandbox and two is uh you only have access to these tools and just run either one.


207
00:28:24.985 --> 00:28:37.985
Yeah. But the end goal is always, I need to like do something And that's why, you know, next week we're going to talk about Asians. And Asians require this knowledge to For you guys to understand it.


208
00:28:37.985 --> 00:28:43.985
How does that sound? Does tool calling make sense to everybody?


209
00:28:43.985 --> 00:28:50.985
Okay, okay. Is anyone doing tool calling right now in their projects?


210
00:28:50.985 --> 00:29:05.985
I am, and I'm using Quinn. I tried using DeepSeq, but I think that there's some sort of incompatibility issue with Landgraph and DeepSeep because when I tried it, it says like DeepSeak does not support tool calling, which I found surprising.


211
00:29:05.985 --> 00:29:11.985
But um


212
00:29:11.985 --> 00:29:12.985
Yeah. Yeah.


213
00:29:12.985 --> 00:29:16.985
Yeah. What did I tell you about like the hidden problems? Langchain is just full of those problems. You gotta like just click, click, click, click, click, and you'll see like some some like half-baked prom that doesn't work with deep sea.


214
00:29:16.985 --> 00:29:34.985
Yep. I'm going to implement your idea about like inserting like a tool calling prompts in multiple places. So there's the system prompt, there's the prompt for the agent and self and you you also said for the description. Can you remind me a real quick where the description description goes?


215
00:29:34.985 --> 00:29:46.985
Yeah. Yeah, system message for the agent or like for your LLM, your router or whatever And then the description, the name of the tool also needs to be very descriptive.


216
00:29:46.985 --> 00:29:57.985
For example, if you have a tool that calls your crum like This is a let's call it like tool to update contact in CRM. Like that's something that has to be very descriptive like that. And then you go to the description


217
00:29:57.985 --> 00:30:03.985
Here, you've got to be very specific about the tool again And then you give examples of when to run the tool.


218
00:30:03.985 --> 00:30:16.985
And then in the parameters, make sure that, you know, whatever arguments you have for the function again reiterate and like just say like this is when to run it and this is how you get the information from the conversation history


219
00:30:16.985 --> 00:30:31.985
Yeah, so just kind of like repeat yourself in the description And can I repeat a little bit more in the parameters And like the system message for the agent.


220
00:30:31.985 --> 00:30:36.985
Yeah. Anyone else?


221
00:30:36.985 --> 00:30:49.985
I think I saw some nods, people using tool calling If you want to give an example of what you're using it for, feel free to unmute yourself and say it.


222
00:30:49.985 --> 00:30:53.985
Everyone decides to be shy, huh? I saw some nods. I'll point you out if you don't repeat yourself.


223
00:30:53.985 --> 00:31:04.985
I can stop. That's a good idea, actually. Feel free to point out, put people on the spot, but I could share my use case.


224
00:31:04.985 --> 00:31:05.985
Mm-hmm.


225
00:31:05.985 --> 00:31:13.985
So… I'm building an agent to research some topic that the user gives.


226
00:31:13.985 --> 00:31:29.985
And one of the, so I'm assuming I will have two tools. One of them is a web search And another one is the writer.


227
00:31:29.985 --> 00:31:30.985
Mm-hmm.


228
00:31:30.985 --> 00:31:56.985
And I'm using OpenAI SDK agents actually after we had a conversation about Which agent framework will last but um So it's an interesting library, actually, because you can use agents as tools as well. But anyway, so… The context is also interesting how you should pass context between those tools as well because mine depends. The second the writer technical tool depends on the context of the


229
00:31:56.985 --> 00:31:57.985
Mm-hmm. Nice. That's the use case right there.


230
00:31:57.985 --> 00:32:06.985
First soul gives me from the web search.


231
00:32:06.985 --> 00:32:13.985
Anyone else?


232
00:32:13.985 --> 00:32:28.985
Honestly, I'm not in the way that you just explained, but I'm kind of making a function call But I would prefer to make it now the way you explained like instead of Right now, it's more of like a workflow for me


233
00:32:28.985 --> 00:32:35.985
Where so my agent is basically uh reviews, pull requests.


234
00:32:35.985 --> 00:32:46.985
Give some suggestions on the git on the pull request on the There's another agent which reads through those comments and incorporates those changes automatically into the code.


235
00:32:46.985 --> 00:33:12.985
So mostly my tools are revolved around github apis where I would need to fetch some details from the pull request code or some tools would be around getting parsing the code and getting some relevant function or class to get some context or something like around that so


236
00:33:12.985 --> 00:33:19.985
At the moment, it's like a workflow, which is very very controlled the way I want.


237
00:33:19.985 --> 00:33:32.985
It's not like orchestrated as such that you know hey, LLM, call this whenever you need have a need So I feel that it's more of like orchestrated flow.


238
00:33:32.985 --> 00:33:33.985
Not like a…


239
00:33:33.985 --> 00:33:40.985
Yeah, I wouldn't change a thing about it. The reason for that is because forcing the model to call only one tool is actually a use case.


240
00:33:40.985 --> 00:33:59.985
And that's why OpenAI has this thing called force tool calling Because tool calling is like a really great way to extract parameters people realized um if you don't do that and you say that, hey, like, I just want it to like


241
00:33:59.985 --> 00:34:18.985
Extract like a list of stuff and then and then you like heuristically pass those values to like a a real function to call after that it's actually not as performant as like hey you have It's not as performant as telling the model, hey, you have access to one tool and this tool takes these arguments


242
00:34:18.985 --> 00:34:23.985
Find the arguments from me from the uh from the conversation.


243
00:34:23.985 --> 00:34:40.985
So… function calling. That's why they made it so there's an option so that there's an option So by default, a model from OpenAI, for example, will not call a tool if the situation doesn't require it to call a tool.


244
00:34:40.985 --> 00:34:45.985
It will actually tell you in in like Natural language.


245
00:34:45.985 --> 00:34:56.985
Just kind of continue the conversation. So for example. You tell it that you have access to like two tools. One is get weather, the other one is stock get stock prices.


246
00:34:56.985 --> 00:35:10.985
And then you say like, who's like… 40th president of the United States and it'll actually like most of the time for like open AI model, it'll just respond back in natural language.


247
00:35:10.985 --> 00:35:14.985
Just like how you would otherwise not have any tools given to it.


248
00:35:14.985 --> 00:35:24.985
But you can have this thing where you can force a to call so that it'll always like get weather or always like get stock prices. So if you ask that question.


249
00:35:24.985 --> 00:35:42.985
It'll actually come up with some weird stuff. To like pass into one of those functions to like force a sket weather or like force get stock prices Which turns out to be very useful in which real world scenarios because real world scenarios


250
00:35:42.985 --> 00:35:52.985
A lot of times the conversation usually hints towards something And user doesn't really like explicitly ask for it.


251
00:35:52.985 --> 00:36:06.985
So in cases like in cases like Hey, like, you know, I'm… I'm asking the model some questions. I'm asking the AI some questions and it doesn't have access to a bunch of stuff But sometimes models are not smart enough


252
00:36:06.985 --> 00:36:22.985
To go online unless you say now go online and search for stuff, then, you know, the tool hit rate is way higher But sometimes we want the model to be like smart enough to know that, hey, we're talking in circle here and just go online and search for stuff.


253
00:36:22.985 --> 00:36:37.985
And that's when like forced toll calling in And that's why like there's some like really interesting patterns where you can do stuff like you have a tool so you have like a AI chat bot or whatever.


254
00:36:37.985 --> 00:36:45.985
And then this chat bot has like um web search tool.


255
00:36:45.985 --> 00:37:02.985
And then what people realize that this is what I do as well is that you can basically… Let the chat bot have a normal conversation with you while having a web search tool by wrapping another tool called another I don't know, conversate.


256
00:37:02.985 --> 00:37:14.985
And then this would actually like based on the situation of the conversation, what was happening in the message's history usually it will know when to call conversate and just talk like a normal chatbot.


257
00:37:14.985 --> 00:37:19.985
And then when when to like call the web search tool.


258
00:37:19.985 --> 00:37:25.985
And then there are some models that you can do web search and then conversate in multiple tools in different steps as well.


259
00:37:25.985 --> 00:37:28.985
Which, if you want to ask me about it, I can show you.


260
00:37:28.985 --> 00:37:35.985
So this is like apparently more performance than just having the web search tool?


261
00:37:35.985 --> 00:37:45.985
And then force it to like talk when it doesn't need to For whatever reason, like these models are not You know, we're just trying to figure out what to do with these models.


262
00:37:45.985 --> 00:37:54.985
That is from what I've known like if you have like this, all of a sudden now it's like good at talking and also decent at using tools.


263
00:37:54.985 --> 00:37:59.985
But if you don't have it, now it's like, don't know when to talk and don't know when to use tools.


264
00:37:59.985 --> 00:38:13.985
So there's a pattern where you're like. You can basically constrain whatever the model is trying to do into like tools so like if you wanted to talk, you have a talk tool. If you wanted to web search, have a web search tool. And if you want it to like


265
00:38:13.985 --> 00:38:20.985
I don't know, reiterate or like talk to her a certain way. You have another… tool so you can even have stuff like, you know.


266
00:38:20.985 --> 00:38:28.985
Conversate and then, you know, conversate like a pirate or something.


267
00:38:28.985 --> 00:38:36.985
So… I think basically like tool calling just means that hey like you are allowed to do these things.


268
00:38:36.985 --> 00:38:49.985
Do the right thing at the right time, basically. And… Yeah, I hope this doesn't confuse you guys too much.


269
00:38:49.985 --> 00:38:55.985
Okay, Oren's like nodding, so I guess this is very confusing.


270
00:38:55.985 --> 00:39:04.985
Just a little bit confusing. Okay, cool. Yeah, so tool cooling gets pretty deep. We'll talk more about it in our agent stuff next week.


271
00:39:04.985 --> 00:39:19.985
And I know some of you guys are already doing tool calling. So cigar, I wouldn't change a thing about it about your workflow If it's supposed to be a workflow, then it's supposed to be a workflow. Don't make it like chain of thought and stuff and then it will go with the wrong tools.


272
00:39:19.985 --> 00:39:27.985
And then you have like a worse performing workflow. I mean, that's just my two cents.


273
00:39:27.985 --> 00:39:40.985
Okay, structure outputs. Anyone wants to… took a jab at this.


274
00:39:40.985 --> 00:39:45.985
I saw Dwayne, unmute him and unmute himself again. This man changed his mind.


275
00:39:45.985 --> 00:39:46.985
Sorry. Oh, sorry.


276
00:39:46.985 --> 00:39:51.985
I was going to say, oh, go ahead. Go ahead.


277
00:39:51.985 --> 00:39:55.985
Thinking about the tool calling again and had a quick question.


278
00:39:55.985 --> 00:40:11.985
So is the, just to reiterate, is the goal of having these tools is to have constraints around what the can do like give it guardrails to what it can do rather than, for example, in my project, it's to retrieve


279
00:40:11.985 --> 00:40:17.985
Information, right? So instead of just giving it to AISDK and be like, oh, retrieve all this for me.


280
00:40:17.985 --> 00:40:24.985
I say that you are this and you can retrieve so and so information based on this and this. So I have a tool around that.


281
00:40:24.985 --> 00:40:26.985
Set that.


282
00:40:26.985 --> 00:40:32.985
Pretty much. And then if you if you're… AI needs to do something else, you just wrap that inside another tool.


283
00:40:32.985 --> 00:40:33.985
Yeah.


284
00:40:33.985 --> 00:40:42.985
And another tool could be like an LLM call. Like, it could be like… just a generate text call like this.


285
00:40:42.985 --> 00:40:47.985
With like a no tools and just like Here's the message's history and just continue the conversation.


286
00:40:47.985 --> 00:40:54.985
The tool can be called Continue the Conversation. And now it cannot do anything outside of like these two things.


287
00:40:54.985 --> 00:40:55.985
Got it.


288
00:40:55.985 --> 00:41:04.985
Which is a great thing to do with tool calling. And you're absolutely right. People use tool coding to do gut rails as well. I do that as well.


289
00:41:04.985 --> 00:41:08.985
Tool calling is just a way to force the model to be like constrained into doing certain things.


290
00:41:08.985 --> 00:41:22.985
And not anything outside of that. Which is great because then I can always have a tool in my router So my router is kind of like basically an LLM call that says like you have a couple of options to continue the conversation.


291
00:41:22.985 --> 00:41:26.985
And one of my tools would be to reject the users.


292
00:41:26.985 --> 00:41:33.985
Requests. And then I have a description for that. It says like, hey, we should find this tool when the user is asking about something inappropriate.


293
00:41:33.985 --> 00:41:49.985
Then that's supposedly like make it more performant when it sees like request that comes in that is not appropriate and then it will actually choose the tool as opposed to like try to reject that by sending back like, hey, as an AI model, I can't do that or whatever.


294
00:41:49.985 --> 00:41:55.985
In that sense, you can also control what you send back.


295
00:41:55.985 --> 00:42:03.985
And then there's a pattern where you can say like. I can wrap these uh I can wrap canned responses in tools as well.


296
00:42:03.985 --> 00:42:13.985
So if you have like a line that you always tell people when they're doing something inappropriate, you can wrap that like you can hard code that into a string and then wrap that inside a tool.


297
00:42:13.985 --> 00:42:25.985
That says respond to inappropriate requests. So that you can say like somebody said something inappropriate, it will run that tool and then you'll always send back like a particular response that you yourself have chosen.


298
00:42:25.985 --> 00:42:28.985
Like, because sometimes you don't want it to say like as an AI model, right? Sometimes you want it to say like.


299
00:42:28.985 --> 00:42:30.985
Yeah.


300
00:42:30.985 --> 00:42:37.985
Oh, you should contact administrator or whatever so that's Now, under your control, right?


301
00:42:37.985 --> 00:42:38.985
Makes sense. Thank you.


302
00:42:38.985 --> 00:42:46.985
So… Yeah. Okay. Dwayne, you want to Do JSON mode real quick or structural output.


303
00:42:46.985 --> 00:43:01.985
By the name of it, I was going to kind of guess that the output So it's a way to make sure that the output that the model gives you is in a specific structure more specific format. I was going to be my guess.


304
00:43:01.985 --> 00:43:08.985
Pretty much. Even though we have the table like this, but structure outputs predate tool calling.


305
00:43:08.985 --> 00:43:23.985
Because we had structure outputs. Which is, you know, if you tell like a model, hey, like return JSON so that, you know, JSON is more friendly to your database format Back in like 2023, 2022, it was really hard to do that


306
00:43:23.985 --> 00:43:37.985
The model would return broken JSON with like, you know, maybe it's missing like a curly bracket at the end or maybe like properties are wrong and stuff like that. But nowadays, most frontier models can do this really well.


307
00:43:37.985 --> 00:43:52.985
So structure outputs just mean, hey, if you want to give me JSON so that it's now structured data for me to use in my either calling in the next function or saving this data into my database That's pretty much it, the structured outputs.


308
00:43:52.985 --> 00:44:04.985
If you use something like Langchain Again, there's a hidden prompt inside of like the um Langchen.


309
00:44:04.985 --> 00:44:09.985
Structured output. Function.


310
00:44:09.985 --> 00:44:16.985
Oh, hold on. Let me find the latest one.


311
00:44:16.985 --> 00:44:28.985
Yeah, so… This right here with structure output, there's like a promise behind that that says You are a JSON expert or whatever. You only return JSON and then say that 10 times.


312
00:44:28.985 --> 00:44:34.985
And then hope that the model will actually do that. There's a problem with like.


313
00:44:34.985 --> 00:44:51.985
Trying to get the model to return a structured output like you know kind of a json like this or a JSON like this. And it always returns like sometimes I return with that like this clear bracket here or something wrong, maybe like a missing quote right here


314
00:44:51.985 --> 00:45:02.985
So what some companies do is that they introduced fine-tuned models, models that I fine-tuned to just do JSON. So OpenAI has one, Gemini has one.


315
00:45:02.985 --> 00:45:07.985
So when I say Gemini, I mean, if you go to Google AI Studio.


316
00:45:07.985 --> 00:45:14.985
And then you're trying to like run a query, what you can do is you can go to the side panel here, as you can see.


317
00:45:14.985 --> 00:45:19.985
They call it function calling, but it's actually tool calling. Just the same thing.


318
00:45:19.985 --> 00:45:24.985
But structure output right here. So you can turn this on and then you can edit it.


319
00:45:24.985 --> 00:45:29.985
Usually you want to give it like a some sort of schema so that you can follow.


320
00:45:29.985 --> 00:45:38.985
So for example, if you want the output to be like, I want it to look like this and then, you know, these properties, these keys are.


321
00:45:38.985 --> 00:45:44.985
What is Oren laughing about?


322
00:45:44.985 --> 00:45:48.985
I was struggling with the structured outputs for two days now.


323
00:45:48.985 --> 00:45:49.985
Oh. Which model are you using?


324
00:45:49.985 --> 00:45:54.985
Only to realize it's right there. Hey, Jimmy.


325
00:45:54.985 --> 00:45:57.985
Okay, so did you give it a schema? Oh.


326
00:45:57.985 --> 00:46:04.985
Not yet, but I was walking on it like half an hour before we started this and I'm going to work on it now.


327
00:46:04.985 --> 00:46:13.985
Okay, so the easiest way to do a schema here is you can code out your JSON here, but I'm like severely dyslexic, so I don't know when to like tab stuff.


328
00:46:13.985 --> 00:46:24.985
So what I do is I usually go to the visual editor And now I can start adding properties. So for example, if your use case like I'm looking at businesses from my web search.


329
00:46:24.985 --> 00:46:32.985
I need to, so I'm scraping a website and then I need just the structure output of like the business, like, you know, business name, business ID, whatever.


330
00:46:32.985 --> 00:46:49.985
So I can type it out like this business name. There should be a string and then you can mark something as required or not required Something like that was required and then maybe like business address optional. And then now if I go back to this, I get a pretty


331
00:46:49.985 --> 00:46:59.985
Pretty nice JSON schema. So this basically tells the model, especially the fine-tuned models from OpenAI or Gemini.


332
00:46:59.985 --> 00:47:04.985
That, hey, this is the format that I want at the end. You need to follow this.


333
00:47:04.985 --> 00:47:11.985
And then if you don't follow this, you will be fine 200 bucks. That might actually work in the prom.


334
00:47:11.985 --> 00:47:19.985
Try that. But yeah, so the model will look at this and be like, okay, I'll try my best to generate something that adheres to this kind of schema.


335
00:47:19.985 --> 00:47:35.985
So easiest way to do it through Gemini is to go on Google AI Studio, click, click, click, click right here, type up, type, type some stuff, and then you have a Jason thing here. Openai has a better thing. And this is what I ran into in my hackathon, I gotta tell you guys.


336
00:47:35.985 --> 00:47:43.985
So when I was doing the hackathon, say, I want to try like the project that I built.


337
00:47:43.985 --> 00:47:56.985
I know some people did. But the tool, basically what it does is it looks at a code base and then it tries to generate a bunch of steps on how to like recreate a feature from that code base.


338
00:47:56.985 --> 00:48:09.985
So that's basically a structured output problem. I want a list of objects from an input string, which is basically the entire code base concatenated into one big string.


339
00:48:09.985 --> 00:48:27.985
So I try to use Gemini. And what happened was, because the code input was so long that by the time it tries to generate the JSON, it always generated with that like missing like stuff and then it turns out that JSON at the end was broken. It couldn't be parsed by like regular code.


340
00:48:27.985 --> 00:48:36.985
So that's the key. If the JSON couldn't be parsed by regular code at the end, that means the JSON is broken and you need to like refine how you do structure output.


341
00:48:36.985 --> 00:48:40.985
So what I did was I knew that OpenAI has this thing called strict mode.


342
00:48:40.985 --> 00:48:49.985
Which means that so they advertise this mode as um You get JSON 100% of the time, guaranteed.


343
00:48:49.985 --> 00:48:58.985
Strict mode. So, for example, we have a similar situation here where we declare like, you know.


344
00:48:58.985 --> 00:49:06.985
So we have a tool here. And then we declare the schema for stuff And then, actually, this is just tool calling a lot.


345
00:49:06.985 --> 00:49:11.985
I need strip mount.


346
00:49:11.985 --> 00:49:17.985
Strict, strict, strict. There we go. So streak mode.


347
00:49:17.985 --> 00:49:25.985
So we still declare like a, you know. Like a JSON object, kind of like what we saw in Gemini.


348
00:49:25.985 --> 00:49:34.985
But in OpenAI, their API has this thing called strict Which means that it will guarantee that a valid JSON will get sent back to you?


349
00:49:34.985 --> 00:49:40.985
100% of the time. I'll get into the caveats to that, but you guys probably won't see it.


350
00:49:40.985 --> 00:49:54.985
But this makes our lives much easier because then you don't have to like catch errors for json which is ridiculous, right? Like sometimes it's missing this, sometimes it's missing that, and then the whole thing breaks but here you can always


351
00:49:54.985 --> 00:50:05.985
Rely on it providing your JSON. Now, if the JSON is valid or not, I mean, the JSON is useful or not, that's another story, but you always get a JSON that doesn't break your code.


352
00:50:05.985 --> 00:50:11.985
Using this thing called strict mode. So for example.


353
00:50:11.985 --> 00:50:19.985
So the caveat of this is that it's slower. So it takes about twice the amount of time to generate.


354
00:50:19.985 --> 00:50:35.985
And the reason for that is because when you turn on streak mode, your request is now hitting a different API. And this API has both a fine-tuned model that does JSON and some heuristic code to kind of like error and backtrack and all that stuff.


355
00:50:35.985 --> 00:50:40.985
So that your JSON will come out to you always valid.


356
00:50:40.985 --> 00:50:56.985
So if you want, like, you know. Kind of worry-free JSON schema structure output, you could always look at strict mode right here If you disable streak mode, it's faster but then There's a 10% chance that it'll be broken.


357
00:50:56.985 --> 00:50:59.985
But if you've turned on streak mode, it will always be valid.


358
00:50:59.985 --> 00:51:13.985
For example, for Gemini if I were to stick with Gemini for my hackathon project, I would have to Just coat just you know regular coat right here Kind of like this.


359
00:51:13.985 --> 00:51:24.985
You know run the call to Gemini, blah, blah, blah, get the JSON. But then at the end, I had to like check whether or not it's a valid JSON. And if it's not a valid JSON, I have to take the error message.


360
00:51:24.985 --> 00:51:30.985
And then pipe it right back to the model to be like, hey, fix this. And then hopefully the second time around, it will be able to fix it.


361
00:51:30.985 --> 00:51:37.985
Yeah, so how does that sound for everybody? This is structured upward.


362
00:51:37.985 --> 00:51:38.985
This is…


363
00:51:38.985 --> 00:51:49.985
Use cases, use cases is just scraping a website and trying to find like the website has like 10 businesses on it and you don't want the string format because you can't save that to your database.


364
00:51:49.985 --> 00:51:53.985
You can do structure output to be like hey I want all this to be a list.


365
00:51:53.985 --> 00:52:03.985
And each item in a list is an object. Now you have a clean list, like save to your database instead of like one long website that's been scraped.


366
00:52:03.985 --> 00:52:25.985
So that's one. Another thing is… you know you're parsing long documents and you're like, oh, I'm just looking for like this particular information piece of information Or I'm just looking for like three key information and you can create a schema that says something like


367
00:52:25.985 --> 00:52:34.985
Address Maybe like somebody sent you like an email and you just wanted the email address.


368
00:52:34.985 --> 00:52:44.985
And then you want like, you know. I don't know. This is kind of like reaching but actionable items And this could be like an array of string or something like that.


369
00:52:44.985 --> 00:52:50.985
Then, you know, you would have an easier time parsing it if it comes back as JSON?


370
00:52:50.985 --> 00:52:55.985
And the whole idea of like a structured output is that it's very friendly to your code.


371
00:52:55.985 --> 00:53:06.985
After the LM. Lm puts out like text and free form text and stuff like that, but it's not very code friendly but friendly If it's structure output, then it's very friendly to the next step you want to do in your


372
00:53:06.985 --> 00:53:10.985
In your pipeline or whatever.


373
00:53:10.985 --> 00:53:18.985
It seems like responses API and OpenAI doesn't have the strict mode.


374
00:53:18.985 --> 00:53:21.985
Oh, that's like the new API from them, right?


375
00:53:21.985 --> 00:53:34.985
Yeah so because i had the similar issue, but I was curious, by the way what do you think about the difference between using base model from Pydantic and just the JSON format?


376
00:53:34.985 --> 00:53:50.985
Base model you can so Pydantic is just a way to declare a schema So the same way you would do with like a TypeScript interface or a Zot schema The reason why some libraries allow you to use Pydantic to like


377
00:53:50.985 --> 00:53:55.985
Declare a schema like this is because it gets converted to this before it hits the model.


378
00:53:55.985 --> 00:54:00.985
Pydantic is just for you. It's for your developer experience.


379
00:54:00.985 --> 00:54:13.985
If you're a Python dev, you would rather be writing identic classes as opposed to like writing this stupid like JSON and you know how many like you know you have to know when to tap, which is like the thing that I hate the most


380
00:54:13.985 --> 00:54:30.985
How many taps is it, right? Like, is this like four or five, right? Like… Unless you have like… ESLint or whatever or like prettier, you wouldn't be able to tell But if you have base model from like Pydantic, then you can just create a class for like


381
00:54:30.985 --> 00:54:49.985
Like this could be a class, right? Parameters could be a class in Pythic. And then in here, instead of declaring like a vomit here, you just say equals to parameter class. And that will be so much nicer than And then the parameter class could be reused somewhere else. So the reason why we use zod and


382
00:54:49.985 --> 00:55:00.985
Typescript and Pydantic is because we can The coat looks nicer. You can reuse those classes in different schemas.


383
00:55:00.985 --> 00:55:10.985
This is basically like hard coding stuff. But this is what the model sees. You're a pattern pedantic class will be converted to this before it hits the model.


384
00:55:10.985 --> 00:55:14.985
I thought they got popular because they're more performant or something.


385
00:55:14.985 --> 00:55:16.985
I don't know why people, I guess it's just the developer experience then.


386
00:55:16.985 --> 00:55:27.985
The model doesn't know what the, I mean, the model knows what a Pydemic class is but like the API endpoint requires you to hit it with a JSON like this.


387
00:55:27.985 --> 00:55:28.985
Cool. Got it.


388
00:55:28.985 --> 00:55:29.985
Yeah.


389
00:55:29.985 --> 00:55:37.985
And do you have to use tool calling to get a structured response, like structured output response, or can we do it without okay


390
00:55:37.985 --> 00:55:46.985
Nope. You can do toe calling with the structure output. You can do toe calling With structure.


391
00:55:46.985 --> 00:55:47.985
Oh, yeah. You can do structure output with that tool calling. So you can have like a basically like a conversation with an AI and be like.


392
00:55:47.985 --> 00:55:53.985
No, no, no, sorry. The other way. I want a structured output, but do I need to It's…


393
00:55:53.985 --> 00:55:59.985
Every time I ask you something, you just kind of respond with a JSON. I only would do that for you.


394
00:55:59.985 --> 00:56:04.985
Okay, so this is, I can bake this structure into my prompt


395
00:56:04.985 --> 00:56:11.985
Yeah, you should. But if you hit open AI models, you send that as part of your schema.


396
00:56:11.985 --> 00:56:26.985
So that would be like something like… Let me see if I can find an example here.


397
00:56:26.985 --> 00:56:27.985
Mm-hmm.


398
00:56:27.985 --> 00:56:36.985
I have shared an example in the chat. That's exactly I was also going to ask you like it's for getting structured output, I was able to use the prompt itself to get me the desired format from the LLM.


399
00:56:36.985 --> 00:56:45.985
Yeah. So usually…


400
00:56:45.985 --> 00:56:46.985
Yeah.


401
00:56:46.985 --> 00:56:52.985
I am doing that right now, but I feel like there are like my it's uh there are issues in how it's getting parsed into my database and I feel like it's probably something to do with my output response not good.


402
00:56:52.985 --> 00:57:02.985
Yes. So they're… two places you have to do it. First is in the system message and the second is in like whatever the property that the API allows you to pass in the schema.


403
00:57:02.985 --> 00:57:17.985
So let me try to find if the… schema 4 because when you hit open ai or if you're using like AI SDK, there's a schema property that you can pass in which hits which gets passed through to OpenAI or to whatever


404
00:57:17.985 --> 00:57:31.985
Model provider. So you need to find that.


405
00:57:31.985 --> 00:57:39.985
Let's see if I can find it. So it usually comes with like the um Oh, it's called generate object. That's what it's called.


406
00:57:39.985 --> 00:57:43.985
Generate object. Yeah.


407
00:57:43.985 --> 00:57:54.985
Yeah, so usually If you hit the OpenAI SDK directly, there's also a schema property. If you hit it through AI SDK, There's a schema property.


408
00:57:54.985 --> 00:58:12.985
And then you can pass your schema here, which is usually a JSON or zot schema And then if you want better performance, you say the whole schema again in your in your um In your prompt it says prom yeah but you didn't have like system message


409
00:58:12.985 --> 00:58:20.985
So basically, you want to kind of like reiterate that you want this particular format.


410
00:58:20.985 --> 00:58:21.985
In the schema property and in the prompt. Ideally.


411
00:58:21.985 --> 00:58:34.985
I wonder if… Yeah, pretty much like just same thing with like function calling. So you can kind of It knows that there are these functions you can call, but then you also want to tell it again. And this is very anecdotally like


412
00:58:34.985 --> 00:58:47.985
I do that. But then again, I don't know. I actually don't know if I should take that out It'll still work just as well. But I think I put that in for this particular reason, which is like it wasn't doing well so i had to like


413
00:58:47.985 --> 00:58:53.985
Can I repeat? When, why, use what and what format in the system message.


414
00:58:53.985 --> 00:58:57.985
Even though I have it in these correct properties.


415
00:58:57.985 --> 00:59:04.985
And my schema here is basically like the database schema, right? So I have to put that in a JSON format.


416
00:59:04.985 --> 00:59:08.985
Yeah, depends on what you're trying to do like trying to save it to a database? Yeah. So it's going to be like.


417
00:59:08.985 --> 00:59:13.985
Yeah.


418
00:59:13.985 --> 00:59:14.985
Yeah.


419
00:59:14.985 --> 00:59:21.985
All the fields of the columns and all the whether it's string or integer and stuff like that for each so Yeah, that's a good question.


420
00:59:21.985 --> 00:59:22.985
Thank you.


421
00:59:22.985 --> 00:59:41.985
Hey, I am wondering given that I've been using prompt template for a while and I've been also retrieving a structured response very consistently. So I'm just wondering why different approaches and why not singular approach.


422
00:59:41.985 --> 00:59:49.985
Like which one to choose then i'm i'm now a little puzzled right now.


423
00:59:49.985 --> 00:59:50.985
Okay.


424
00:59:50.985 --> 00:59:59.985
We're getting good performance and don't change anything. Yeah. If you don't, then now we're going to enter the territory of experimentation That's the name of the game.


425
00:59:59.985 --> 01:00:09.985
That's why we have like prompt optimization library stuff. Because if it works like… That's amazing.


426
01:00:09.985 --> 01:00:16.985
Keep doing that. If it doesn't work, then… There are a couple options you have.


427
01:00:16.985 --> 01:00:23.985
Yeah, I wouldn't add more stuff if it's already working.


428
01:00:23.985 --> 01:00:36.985
Anyways… You guys want to stick around. Maybe I'll set up some tool calling and structured output after the call.


429
01:00:36.985 --> 01:00:38.985
And we want to say after the call, I mean like now.


430
01:00:38.985 --> 01:00:42.985
If you want to stick around, stick around for that. If not.


431
01:00:42.985 --> 01:00:47.985
Feel free to leave.


432
01:00:47.985 --> 01:00:52.985
Yeah. How's that sound?


433
01:00:52.985 --> 01:01:04.985
Okay, cool. Actually, before we end the lecture Let's go back to Figma. I want you guys to populate the… What's the tool calling and structure output table?


434
01:01:04.985 --> 01:01:17.985
From what you learned today. And if you know more than your classmates, feel free to put stuff in there because Everyone's trying to learn, so…


435
01:01:17.985 --> 01:01:25.985
This is so cool that we can write in the same environment. I just love this.


436
01:01:25.985 --> 01:01:35.985
Is this their first time doing remote work, Mary? I really hate this stuff, by the way. When I pull up slack or like figma i get anxiety Spring spike memories.


437
01:01:35.985 --> 01:01:46.985
Why?


438
01:01:46.985 --> 01:02:16.985
That guardrail piece for tool calling is such a… hidden gem.


439
01:02:20.985 --> 01:02:34.985
While you guys are doing that, keep doing that. I'm going to pull up the… code for for stuff.


440
01:02:34.985 --> 01:02:38.985
Oh, this is my hackathon project. That's so funny.


441
01:02:38.985 --> 01:02:42.985
Are you going to open source it?


442
01:02:42.985 --> 01:02:49.985
I might. I might.


443
01:02:49.985 --> 01:02:56.985
I'm trying to think what to do with it. Like so a bunch of VCs like reached out After my presentation, after my pitch.


444
01:02:56.985 --> 01:02:59.985
And they were like, oh, I need this stuff like two weeks ago.


445
01:02:59.985 --> 01:03:04.985
Me and the team is trying to copy some features from like a very popular open source project. So, like.


446
01:03:04.985 --> 01:03:13.985
Let's chat. Let's chat.


447
01:03:13.985 --> 01:03:24.985
And it was difficult because this is like a developer tool right so have the VCs in the room were like non-technical So I had to really dumb it down.


448
01:03:24.985 --> 01:03:39.985
So I just say like, oh, you know, when your team is like The team of developers is like trying to like replicate a feature from somewhere else and You can reduce that time from like seven days to like one day because this will just tell you what to replicate


449
01:03:39.985 --> 01:03:43.985
And then half of them were like somewhat technical. So that was easier.


450
01:03:43.985 --> 01:03:47.985
We'll put the circle over here.


451
01:03:47.985 --> 01:03:55.985
Yeah. Oh, did I delete somebody's circle? Was it supposed to be there?


452
01:03:55.985 --> 01:04:01.985
If it wasn't, my apologies. Anyways, I'm going to pull up.


453
01:04:01.985 --> 01:04:06.985
About the…


454
01:04:06.985 --> 01:04:07.985
Yep.


455
01:04:07.985 --> 01:04:15.985
Hi, I had a question. Just thinking about a use case in my project and maybe I can reiterate that and you can correct me if I'm thinking the right way.


456
01:04:15.985 --> 01:04:16.985
Hmm.


457
01:04:16.985 --> 01:04:21.985
So let's say I have multiple sources to call or like cross referencing multiple apis so Is it a good thing that I'm using?


458
01:04:21.985 --> 01:04:27.985
Yep. Yes.


459
01:04:27.985 --> 01:04:28.985
Yes.


460
01:04:28.985 --> 01:04:33.985
Calling for like, I want this application to be called for certain topic and not for like something like that


461
01:04:33.985 --> 01:04:48.985
Yes. And the team at Weeviate called it agentic rack. So you basically you wrap the source of knowledge inside of a tool and then you tell it when to call the source of knowledge.


462
01:04:48.985 --> 01:04:55.985
So it's a known pattern.


463
01:04:55.985 --> 01:05:03.985
Like I can give it a structured query with JSON, like abstract title


464
01:05:03.985 --> 01:05:12.985
I'm just going to tell it the structure it is for your arguments or your parameters.


465
01:05:12.985 --> 01:05:20.985
Where's the getting started repo? Try and find it.


466
01:05:20.985 --> 01:05:22.985
Is it this one? No.


467
01:05:22.985 --> 01:05:28.985
What was there? Getting started? The couch desk, the vibe.


468
01:05:28.985 --> 01:05:37.985
Like the very first repo that i made In the first lecture where I set up like light LLM and AI SDK. I don't know where.


469
01:05:37.985 --> 01:05:41.985
You probably did on your own workshop repo, actually.


470
01:05:41.985 --> 01:05:46.985
Oh.


471
01:05:46.985 --> 01:05:48.985
Their bootcamp.


472
01:05:48.985 --> 01:05:57.985
Okay. Okay. I don't know if I have it on my computer.


473
01:05:57.985 --> 01:06:12.985
Ai workshop. Yay. Okay, so we got this i'm gonna No, we can't, I think.


474
01:06:12.985 --> 01:06:16.985
He…


475
01:06:16.985 --> 01:06:23.985
Start. Okay. No, it's not it.


476
01:06:23.985 --> 01:06:30.985
Where am I? Where am I right now? Well, Malware now. Oh, I have two files. Okay.


477
01:06:30.985 --> 01:06:44.985
Now it starts to come back to me. Okay, we pulled out this starter code and then we're going to do some stuff.


478
01:06:44.985 --> 01:06:48.985
I'm glad I had this so I don't have to like set up everything again.


479
01:06:48.985 --> 01:06:54.985
Okay, zoom in real quick.


480
01:06:54.985 --> 01:07:12.985
Okay, so this is like… very quick ai sdk like write a short… poem. So instead of doing this What we're going to do is we're going to set up a function to I wonder if I should do tool calling


481
01:07:12.985 --> 01:07:21.985
Structure output. So tool calling is basically structure output. It's a structured output of the name of the function and then the arguments that go into the function.


482
01:07:21.985 --> 01:07:27.985
So let's do structure output first because that predates tool calling.


483
01:07:27.985 --> 01:07:34.985
So let me pull up the documentation for AI SDK right here.


484
01:07:34.985 --> 01:07:42.985
So when you're using the AI SDK, There are many ways to generate stuff.


485
01:07:42.985 --> 01:07:50.985
When you want to generate text, you call the generate text method from the AI SDK library like this.


486
01:07:50.985 --> 01:07:57.985
When you want to do just structured outputs, you use generate object.


487
01:07:57.985 --> 01:08:04.985
So this is what we're going to be using. So I'm going to do this, go back here.


488
01:08:04.985 --> 01:08:10.985
We got generate text Okay, cool.


489
01:08:10.985 --> 01:08:20.985
But what I want to do is I want to create another file here Perhaps I call this Structured output.


490
01:08:20.985 --> 01:08:29.985
Example.js because this is a javascript pre-bill for whatever reason.


491
01:08:29.985 --> 01:08:36.985
My brother in Christ, you made the repo. I made the repo.


492
01:08:36.985 --> 01:08:50.985
Okay, so to do structure outputs, you… You can do like the regular JSON stuff, which is very ugly, right? But in Next.js or in TypeScript or JavaScript, you can use this library called Zod.


493
01:08:50.985 --> 01:08:53.985
Does anyone here is using the Za right now or no?


494
01:08:53.985 --> 01:09:00.985
Okay, I see one hand. Dwayne, you're shaking your head. This all will make your life easier.


495
01:09:00.985 --> 01:09:08.985
Cursor is also very familiar with Zod. This is how you would create a schema in Zot.


496
01:09:08.985 --> 01:09:21.985
It's very clean. If you were to do this in like street JSON, then it's going to be balloon and then you can't reuse some of the schemas in different schemas.


497
01:09:21.985 --> 01:09:25.985
So use R, that's what I'm trying to say. It's recommended by OpenAI.


498
01:09:25.985 --> 01:09:32.985
So I'm going to be doing this. So I guess… important zod as well.


499
01:09:32.985 --> 01:09:40.985
And then I'm just going to say I guess I need a schema first.


500
01:09:40.985 --> 01:09:47.985
What am I trying to do? So my input, my input would be something like, um.


501
01:09:47.985 --> 01:09:53.985
A website or something. Our website.


502
01:09:53.985 --> 01:10:05.985
Html. See, it works with HTML and like Markdown and all that stuff too. If you pass the HTML and you're trying to get like structured output, it usually works with a strong enough model.


503
01:10:05.985 --> 01:10:11.985
And then the output I want it to be I wanted to find that.


504
01:10:11.985 --> 01:10:17.985
I wanted to figure out what website i want to Extract first.


505
01:10:17.985 --> 01:10:26.985
Do you guys have a website that you want to like… extract information from?


506
01:10:26.985 --> 01:10:33.985
I'm trying to extract a describe a lot of recipes so maybe series eats.com or something


507
01:10:33.985 --> 01:10:34.985
You call it serious eats? Yeah.


508
01:10:34.985 --> 01:10:38.985
Yeah.


509
01:10:38.985 --> 01:10:45.985
So we're going to pick um


510
01:10:45.985 --> 01:10:49.985
I like how it doesn't just give me like a recipe.


511
01:10:49.985 --> 01:10:55.985
None of this is recipes. Oh, there you go. Recipe. Ooh.


512
01:10:55.985 --> 01:11:06.985
I don't know so many things to choose. Um… This one looks nice. Okay, let's say we want this.


513
01:11:06.985 --> 01:11:12.985
The quick and dirty way is that I want to Let's just pretend we have a tool to scrape the web.


514
01:11:12.985 --> 01:11:23.985
We don't have it built in, so I'm just going to go to file crawl, which is a web scraping tool. I'm just going to paste the thing in and then What I'm going to do is I'm going to get the markdown content back


515
01:11:23.985 --> 01:11:28.985
Or I think I promised you guys HTML. So I'm actually going to do that.


516
01:11:28.985 --> 01:11:34.985
Include HTML content. There you go. Run again.


517
01:11:34.985 --> 01:11:45.985
So I'm going to hit that website. It's going to bring back both the markdown and the HTML. So this HTML It's incredibly dense, incredibly long.


518
01:11:45.985 --> 01:11:50.985
But with a good enough model, we can definitely get the response back.


519
01:11:50.985 --> 01:12:00.985
I'm going to copy that and then I'm going to make new file here. I'm going to say um Recipe.


520
01:12:00.985 --> 01:12:21.985
Data or something like that. Recipe. Recipe. Okay, so… I want to say this, and then I'm going to give it a… basically a string and i want it to be So I use the string literal so that I can kind of do this. Why use…


521
01:12:21.985 --> 01:12:26.985
Quotes it will not do that for you. This is basically the website.


522
01:12:26.985 --> 01:12:29.985
So I'm going to save it in this in here. It's called recipe.


523
01:12:29.985 --> 01:12:38.985
Bring it back in here so the input would be this basically. So I'll say.


524
01:12:38.985 --> 01:12:49.985
Import recipe from I'm going to say… Dot slash recipe. Thank you very much.


525
01:12:49.985 --> 01:13:03.985
And then the output of this. What I want it to look like is I want… Probably, I'm going to scroll down to the steps.


526
01:13:03.985 --> 01:13:11.985
Maybe ingredients and then directions. Directions could be a list of string Each step is a string.


527
01:13:11.985 --> 01:13:18.985
And then… Okay.


528
01:13:18.985 --> 01:13:25.985
You know what? This is the part where you use… cursor because I don't want to type all this stuff.


529
01:13:25.985 --> 01:13:36.985
So I'm going to pull up chriser and be like… you'll make me… a zod schema for… recipe.


530
01:13:36.985 --> 01:13:49.985
I need the following fields required. And then I need… Ingredients.


531
01:13:49.985 --> 01:13:55.985
List of string i need uh steps.


532
01:13:55.985 --> 01:14:09.985
List of string. And I need maybe like… time. And then I need… Time would just be like… Seconds.


533
01:14:09.985 --> 01:14:21.985
And this would be a number. And then I need maybe something like…


534
01:14:21.985 --> 01:14:33.985
What else? What else would Ward I care about when I make this?


535
01:14:33.985 --> 01:14:45.985
It's historical significance. Why? Like, why? Why should someone make this?


536
01:14:45.985 --> 01:14:51.985
And because we're dealing with AI, we're just going to let it know So that can kind of bite that in.


537
01:14:51.985 --> 01:14:58.985
Maybe we can make like an effort level difficulty or something.


538
01:14:58.985 --> 01:15:08.985
Okay, I like that. I actually don't know if it's in here, which is a good kind of example to see if Okay, maybe it couldn't find anything like what what is it going to do And we can maybe try to optimize them.


539
01:15:08.985 --> 01:15:13.985
Like the amount of ingredients or the amount of time some sort of a combination maybe.


540
01:15:13.985 --> 01:15:29.985
Yeah. But I do want to see this because I want to see like, okay, so how is it going to deal with not being able to find information from the text Okay, so we got the zod schema for recipe here and then


541
01:15:29.985 --> 01:15:39.985
We have to delete that because if If the field that's required and it doesn't pass anything in, that's when our code breaks.


542
01:15:39.985 --> 01:15:54.985
Actually, no, that's not when our code breaks. That's when the AI provider will send back an error and be like, yo we couldn't generate anything because we couldn't generate anything because There was one field that was required where we couldn't do anything about it.


543
01:15:54.985 --> 01:16:01.985
So… Sin.


544
01:16:01.985 --> 01:16:10.985
So just a quick look at my setup. I got 3.7 sonnet.


545
01:16:10.985 --> 01:16:11.985
Yep.


546
01:16:11.985 --> 01:16:20.985
While it's working, a quick question. Hi. For your hackathon, how did you manage to afford the tokenization cost for while reading huge codebases?


547
01:16:20.985 --> 01:16:31.985
I mean you like even reading one project it would have costed you. So did you made any optimizations while reading those code bases or


548
01:16:31.985 --> 01:16:48.985
Yeah, I use this tool called rebo max And there's a flag that you can enable where you can compress the the structure of the code without it losing its relationship for some reason I think, for example.


549
01:16:48.985 --> 01:16:54.985
What it does, it basically treats certain functions Unless they are significant and used a lot.


550
01:16:54.985 --> 01:17:05.985
It treats certain functions as like an abstract function. So it takes basically it keeps the It keeps the function name and the parameters and the return output and just leave everything in the middle blank.


551
01:17:05.985 --> 01:17:10.985
So like you almost like treat it as like, no, there's no implementation, but you kind of know when to use it.


552
01:17:10.985 --> 01:17:11.985
So there's compress mode. And also like i some i A lot of people use this.


553
01:17:11.985 --> 01:17:16.985
I see.


554
01:17:16.985 --> 01:17:22.985
Burn like $17 overnight. So I don't think… I don't think…


555
01:17:22.985 --> 01:17:27.985
But which tool sorry to interrupt you which tool did you mention the name


556
01:17:27.985 --> 01:17:33.985
It's called Repo Max. Let me pull mix, my bet.


557
01:17:33.985 --> 01:17:34.985
Okay.


558
01:17:34.985 --> 01:17:43.985
You can use this locally to like just run it against your code base and now you get like a Markdown on pretty much all the stuff in your code base.


559
01:17:43.985 --> 01:17:52.985
Yep. Anyways, going back to this, we got the recipe schema Which looks fine. We're not here yet. Delete this.


560
01:17:52.985 --> 01:18:07.985
Except. Recipe schema. Okay, so we're going to go back to our documentation here. So what I'm seeing here is I'm seeing a constant result here. And then this is an asynchronous function. So we have to await it.


561
01:18:07.985 --> 01:18:25.985
So I'm just going to copy this right here going out here and I'm just going to say Okay, so I need to pass something into this generate object function So what goes in here? What goes in here? Okay, we've got to pass in the model. So first we're passing the model.


562
01:18:25.985 --> 01:18:33.985
Model, I'm going to say GPT 4.0. Spurn some money.


563
01:18:33.985 --> 01:18:38.985
And then what do you want? Oh.


564
01:18:38.985 --> 01:18:45.985
It's supposed to be an object, my guys. There you go.


565
01:18:45.985 --> 01:19:01.985
Model. And then I think next thing is default object generation mode json Okay, so since this is OpenAI and I just told you guys about strict mode, I wonder if I can pass in strict in here.


566
01:19:01.985 --> 01:19:09.985
Yes, I can. Go away. Let's see.


567
01:19:09.985 --> 01:19:20.985
Let me actually look that up. I don't know if that's true. I don't know if my linter is working well, so… Let me just double check and see if streak mode goes in there.


568
01:19:20.985 --> 01:19:27.985
Should I look up Generate object here.


569
01:19:27.985 --> 01:19:39.985
Because we want the documentation for testing it's different Okay, schema goes into this. So schema goes into the schema property And I hope you guys watch me do this.


570
01:19:39.985 --> 01:19:47.985
Because I'm like looking at documentation. I don't know these things off the top of my head, right? So… You can totally do what I'm just doing right now.


571
01:19:47.985 --> 01:19:55.985
And then you'll get there. You feel like, oh, there's a lot of stuff. Like, look at me. I'm just literally just reading the docs and trying to one stamp at a time.


572
01:19:55.985 --> 01:20:01.985
So schema, we pass in the recipe schema over here, which we've declared with the Zod.


573
01:20:01.985 --> 01:20:20.985
If you want to write ZART by hand, use AI. It's pretty straightforward. And then the prompt goes down here. So I wonder if I can find the strict mode in here so in here As you see, whenever I have a question about something, I'm usually just looking in through the documentation and see if I can find it.


574
01:20:20.985 --> 01:20:25.985
So I type in strict and down here I see structure output from OpenAI.


575
01:20:25.985 --> 01:20:33.985
Structured output true. Okay.


576
01:20:33.985 --> 01:20:39.985
Okay, okay. Pdf support.


577
01:20:39.985 --> 01:20:50.985
Upwards. Okay, so all it's saying here is that it says as long as I have the structure outputs to true here I'll be fine.


578
01:20:50.985 --> 01:20:55.985
Which is not true. And I'm going to cheat a little bit because I looked at this during my hackathon.


579
01:20:55.985 --> 01:21:01.985
There's a property that I can pass in to get Truly, truly streak mode.


580
01:21:01.985 --> 01:21:05.985
So here, let me pull up my hackathon project real quick.


581
01:21:05.985 --> 01:21:11.985
Strict. There we go.


582
01:21:11.985 --> 01:21:23.985
So this also uses the AI SDK. And… I have to declare a strict mode in the OpenAI model client, basically.


583
01:21:23.985 --> 01:21:34.985
So I can't do that in the generate Let me pull up the other code again. I can't do in the generate object method from AI SDK. I have to do it earlier in that.


584
01:21:34.985 --> 01:21:39.985
So I have to do it when I create the open AI model object.


585
01:21:39.985 --> 01:21:48.985
So let me scroll up here real quick. Create OpenAI from AI SDK slash open AI. Okay, so I need that.


586
01:21:48.985 --> 01:21:58.985
I'm going to pass that in here. I don't know if I installed this though. Let's see There's no way for me to know. That's great.


587
01:21:58.985 --> 01:22:07.985
And then… This is where I use this. Go down to where I use it. And then I have to do this.


588
01:22:07.985 --> 01:22:16.985
So there's a property called compatibility And then I had to pass in the key strict here.


589
01:22:16.985 --> 01:22:25.985
The value strict here to this key. So that's how you get strict mode in OpenAI when you're using OpenAI. I mean, you're using AI SDK.


590
01:22:25.985 --> 01:22:33.985
Very hard to find, but now you know. Because I did find this when I was doing it.


591
01:22:33.985 --> 01:22:40.985
Okay, so going back to this. Now we're pretty much good to go.


592
01:22:40.985 --> 01:22:43.985
I don't know if we can still need to pass instructor output true.


593
01:22:43.985 --> 01:22:49.985
Did I do it here? I don't think so. And it worked fine.


594
01:22:49.985 --> 01:22:50.985
So you need the prompt.


595
01:22:50.985 --> 01:22:59.985
So I think. Yes, we need to prompt. I'm trying to see if I need to like, you know, do like the thing that the documentation says. It says like structure outputs true.


596
01:22:59.985 --> 01:23:05.985
So it seems like I don't have to. When I have my strict mode enabled.


597
01:23:05.985 --> 01:23:15.985
Yeah, so… the prompt. The prompt is the prompt Well, the AI has already written the prompt for me, which is great.


598
01:23:15.985 --> 01:23:36.985
Extract the following. Let's extract the recipe information from the provided html Return a structure in JSON with Looks great. Looks great. And the HTML here does not exist. So we're going to have to like figure out How to pass that in. We already have that right here. It's called recipe.


599
01:23:36.985 --> 01:23:47.985
So we got recipe here. Okay, why the heck is it doing this okay Okay. I don't know why it's like format like this is funny.


600
01:23:47.985 --> 01:23:54.985
But this is basically our website so it's good. We haven't.


601
01:23:54.985 --> 01:24:01.985
All right, so… That being said, we have the schema passed in. We have a prompt here.


602
01:24:01.985 --> 01:24:13.985
That tells it to extract some stuff. And we've got strict mode on. And I'll do one with that strict mode on so that you guys can see what it looks like.


603
01:24:13.985 --> 01:24:17.985
And… Yeah.


604
01:24:17.985 --> 01:24:22.985
Thank you, AI. That's pretty much it. That's about it.


605
01:24:22.985 --> 01:24:32.985
Go to my terminal. And then this is in bootcamp AI SDK. So I'm just going to city in bootcamp AI SDK.


606
01:24:32.985 --> 01:24:43.985
And I think I'm just going to have to do a note and then structured output I think last time I ran this, I need to add some stuff in the beginning. So let me see if I need that.


607
01:24:43.985 --> 01:24:49.985
So… Here we have the… Actually, I don't need to do anything.


608
01:24:49.985 --> 01:25:04.985
That's great, but I do need to do this, I remember from last time because… Because we're running this script on its own, it needs to load like the um the virtual and the environment variables which contains the open api key


609
01:25:04.985 --> 01:25:10.985
If we don't do this, we didn't have it last time. So I think we'd struggle with that for a little bit.


610
01:25:10.985 --> 01:25:16.985
Other than that, I think we're good to go. Yeah. Save.


611
01:25:16.985 --> 01:25:27.985
And then I'm going to run this and something's going to happen obviously It says, cannot find package AI imported from blah, blah, blah, blah, blah.


612
01:25:27.985 --> 01:25:33.985
Well, why is that? Oh, because it's a new computer. I didn't PNPM install.


613
01:25:33.985 --> 01:25:38.985
Psych. It's almost like there's always some stuff that is just in the way, right? Always.


614
01:25:38.985 --> 01:25:44.985
It's the nature of the job. And then I do this for four hours a day and I get pissed by the end.


615
01:25:44.985 --> 01:25:49.985
I need to go and blow some steam. Okay, so PNPMI.


616
01:25:49.985 --> 01:25:56.985
Boom, done. Now we got the note modules. Now we know we've installed some stuff here.


617
01:25:56.985 --> 01:26:16.985
Run this again, please. Of course, something else happens. We need Zod. We don't have Zod. It's 9.30. Just… AI, I don't know, like, I don't… Yeah, one day we will have this bigger app for us. Oh, we have an error? Maybe just do that for you real quick.


618
01:26:16.985 --> 01:26:32.985
I'll fix that for you. What else? What else do we need? Oh, yeah. Okay. So because we're running this as a script, we need And we didn't specify in our package.json, this is supposed to be a module I believe that's why we need to basically


619
01:26:32.985 --> 01:26:41.985
Do this. And if you're using Next.js, you don't have to worry about any of this stuff because when you instantiate a project in next everything is just taken care of for you.


620
01:26:41.985 --> 01:26:47.985
Typescript types, everything, TypeScript config All that stuff. Easy.


621
01:26:47.985 --> 01:26:56.985
What else do we need to do here? I will not touch this code base ever again. I'm going to pull up like Next.js next time because this is just wasting my time.


622
01:26:56.985 --> 01:27:10.985
What else? Require is not defined ES module scope you can use I was trying to accommodate I was trying to accommodate and port Thank you. There you go.


623
01:27:10.985 --> 01:27:17.985
Do I need this? Maybe I do. Ron. Okay. Something else happened.


624
01:27:17.985 --> 01:27:24.985
Model does not have a default object generation mode. Okay, what do you mean by that?


625
01:27:24.985 --> 01:27:28.985
We have to pass this in. It's dim.


626
01:27:28.985 --> 01:27:34.985
There you go. I believe that's how it's supposed to work. There we go.


627
01:27:34.985 --> 01:27:40.985
Perfect. Ron. Okay. What else? What's going on?


628
01:27:40.985 --> 01:27:46.985
Swear to God. Three… What?


629
01:27:46.985 --> 01:27:58.985
Module type. It's not specified it doesn't specify parse as common js Which file is this?


630
01:27:58.985 --> 01:28:07.985
Structure output example okay Reparsing as ES module because model does not have a default object.


631
01:28:07.985 --> 01:28:15.985
Wait. This is an old… Hold on.


632
01:28:15.985 --> 01:28:19.985
Hmm. This happens again. What the heck?


633
01:28:19.985 --> 01:28:21.985
I thought I passed something in. Open the eye right here.


634
01:28:21.985 --> 01:28:28.985
What are you talking about? Oh, I need to give it a model name, I think.


635
01:28:28.985 --> 01:28:33.985
Okay, let me pull up my hackathon code again. Where do I declare it? Oh, there we go.


636
01:28:33.985 --> 01:28:42.985
That's different. So OpenAI object goes into provider Options. Okay. Okay.


637
01:28:42.985 --> 01:28:46.985
No, actually, that's not true. Let me backtrack that real quick.


638
01:28:46.985 --> 01:28:57.985
This goes where? This goes where?


639
01:28:57.985 --> 01:29:09.985
Model model is supposed to supposed to be, oh, the model is when you use this to wrap the name My God.


640
01:29:09.985 --> 01:29:17.985
Okay, so I need a model right here and the model is for GPT. Thank you.


641
01:29:17.985 --> 01:29:23.985
And then pass the model down here. I can't just pass the open AI object down there.


642
01:29:23.985 --> 01:29:27.985
All right. What else?


643
01:29:27.985 --> 01:29:36.985
Openai API key is missing. Bro, that's why I have the freaking thing here.


644
01:29:36.985 --> 01:29:42.985
Okay. So I knew index.js worked.


645
01:29:42.985 --> 01:29:49.985
I knew that from last time. So what did I do in here that was different?


646
01:29:49.985 --> 01:29:52.985
Like other than this, can I just have this in here?


647
01:29:52.985 --> 01:29:57.985
I think so. I think so.


648
01:29:57.985 --> 01:30:03.985
But it's like, no. What's happening here, Chad?


649
01:30:03.985 --> 01:30:07.985
Does anyone know?


650
01:30:07.985 --> 01:30:14.985
Okay. This doesn't parse as a common JS module.


651
01:30:14.985 --> 01:30:23.985
Well, then why does this parse as a common JS module? I didn't do anything different.


652
01:30:23.985 --> 01:30:30.985
Let me think for a sec. Oh, I think I know why.


653
01:30:30.985 --> 01:30:36.985
We all use require here, but in here we use like regular stuff, which is not what we're supposed to do.


654
01:30:36.985 --> 01:30:42.985
I don't got time to change all this. I'm just going to say like use require here for me.


655
01:30:42.985 --> 01:30:50.985
Please. Thank you very much. Looks about right.


656
01:30:50.985 --> 01:30:55.985
It's like ticking back 20 years. Oh.


657
01:30:55.985 --> 01:31:01.985
Requires that what do you mean? I thought this is what you wanted.


658
01:31:01.985 --> 01:31:07.985
Okay. Then go in here and see this real quick.


659
01:31:07.985 --> 01:31:17.985
Um.


660
01:31:17.985 --> 01:31:24.985
Honestly, honestly. I'm going to pass this AI. I don't want to deal with this right now.


661
01:31:24.985 --> 01:31:33.985
So if you're on Next.js, you have to think about what I'm doing right now because this is just a script running on its own.


662
01:31:33.985 --> 01:31:41.985
So now we're going to let AI deal with this stuff.


663
01:31:41.985 --> 01:31:44.985
So the problem is this is running as a script in Node.


664
01:31:44.985 --> 01:31:51.985
And I don't remember if I declared the configuration for it to be an ES module or not.


665
01:31:51.985 --> 01:31:54.985
And I'm too lazy to find out right now because it's 9.30.


666
01:31:54.985 --> 01:31:59.985
So Krista is going to help me Okay.


667
01:31:59.985 --> 01:32:03.985
So if it's bringing back the import statements


668
01:32:03.985 --> 01:32:10.985
I don't know if that's how it's supposed to work.


669
01:32:10.985 --> 01:32:16.985
But then when we add the type module to the packages on the other file is probably not going to work.


670
01:32:16.985 --> 01:32:32.985
But we can try that. So we have web add type module to package.json now it's treated as an ES module so they can do like the modern type JavaScript stuff instead of this like backwards


671
01:32:32.985 --> 01:32:39.985
Where do I hide? Do you give like context more than that file? Can you give like the entire folder?


672
01:32:39.985 --> 01:32:40.985
The context of the agent.


673
01:32:40.985 --> 01:32:46.985
Yep. Yep. You can drag a full folder in.


674
01:32:46.985 --> 01:32:54.985
Okay, no need to run this. I will just, I will just accept whatever you just wrote.


675
01:32:54.985 --> 01:33:11.985
So what it changed was the type module, which is a configuration silliness that has consequences, but whatever we'll accept that And then here we just switch it back to import statements here so that Because now this is treated as an ES module.


676
01:33:11.985 --> 01:33:16.985
So let me run this again. Swear to God. What?


677
01:33:16.985 --> 01:33:23.985
What? Oh, do I not? Oh, this is a new computer. Why do I keep thinking? I don't have a .env file in here.


678
01:33:23.985 --> 01:33:30.985
Chat. My brain is so cooked right now. Okay. Env.


679
01:33:30.985 --> 01:33:38.985
It's like the error message is accurate. And I'm like, no, you don't know what you're talking about.


680
01:33:38.985 --> 01:33:43.985
I don't know what I'm talking about.


681
01:33:43.985 --> 01:33:46.985
Mary, are you seeing me having a mental breakdown on live?


682
01:33:46.985 --> 01:33:48.985
Yeah, I'm actually laughing behind the mute.


683
01:33:48.985 --> 01:33:55.985
Oh, it's still on? Okay, cool. Getting my API key real quick.


684
01:33:55.985 --> 01:34:05.985
Api key. Starter Boot Camp. Bootcamp 2.


685
01:34:05.985 --> 01:34:21.985
Create secret key copy Go down here, the API key equals to this string right here close uh run it again Yay. No.


686
01:34:21.985 --> 01:34:42.985
God. What? What is it this time? Oh, okay. This module maximum context is 28,000 tokens 137,000 tokens Okay, so we got to find another recipe, my guy. It's too much.


687
01:34:42.985 --> 01:34:47.985
Let's do less serious eats. I'll give you something. And…


688
01:34:47.985 --> 01:34:51.985
Actually, before we do that, let me do that I have second thoughts. I have second thoughts here.


689
01:34:51.985 --> 01:34:58.985
Okay, now we can continue. That's a lot of tokens, bro. Okay.


690
01:34:58.985 --> 01:35:06.985
I'm down to do another recipe. I'm about to like copy less of this.


691
01:35:06.985 --> 01:35:07.985
That's a lot, yeah.


692
01:35:07.985 --> 01:35:11.985
So, yeah, because like, oh. A lot of this is just like the SVG icons and stuff I'd take something.


693
01:35:11.985 --> 01:35:13.985
Yeah, I don't know why.


694
01:35:13.985 --> 01:35:18.985
Well, that's the raw HTML. But if you want like clean markdown, you can do this.


695
01:35:18.985 --> 01:35:26.985
Which is like, you know, pretty easy for a model I guess I was trying to like see if the model can like just look at straight HTML and do it.


696
01:35:26.985 --> 01:35:31.985
I can just copy half of it. I don't know which half.


697
01:35:31.985 --> 01:35:39.985
Just pick a different page.


698
01:35:39.985 --> 01:35:40.985
Let's see.


699
01:35:40.985 --> 01:35:51.985
I think… They're all going to have these like SVGs. We're not going to be able to But, you know, we can just choose because 128,000, right? And it was 137,000 tokens so If I take up half of it, it should be


700
01:35:51.985 --> 01:35:52.985
Plenty of room. Yeah, let me use this.


701
01:35:52.985 --> 01:35:56.985
Yeah, you can cut all the sheet and yeah


702
01:35:56.985 --> 01:35:57.985
Ooh. Some creep.


703
01:35:57.985 --> 01:36:02.985
What kind of recipe is that? My gosh.


704
01:36:02.985 --> 01:36:03.985
Okay. Something very technical.


705
01:36:03.985 --> 01:36:07.985
Something very technical.


706
01:36:07.985 --> 01:36:13.985
Boom. Recipe in here. Boom, save.


707
01:36:13.985 --> 01:36:14.985
Foodful machines.


708
01:36:14.985 --> 01:36:23.985
All right. Running this again. Boom. Now we're talking. Now it's loading.


709
01:36:23.985 --> 01:36:27.985
All right, start betting. Go and polymarket. Is this going to air out again?


710
01:36:27.985 --> 01:36:29.985
I doubt it. If it airs out again, I'm just going to end. Oh, my God.


711
01:36:29.985 --> 01:36:32.985
I got 50. I'm still.


712
01:36:32.985 --> 01:36:33.985
Let's go.


713
01:36:33.985 --> 01:36:39.985
Oh my God. What happened?


714
01:36:39.985 --> 01:36:48.985
Oh, right. It was a good um generation. We just didn't parse it in our Response?


715
01:36:48.985 --> 01:36:52.985
That's why it gave us like a whole bunch of stuff here.


716
01:36:52.985 --> 01:37:05.985
The key is object. I'm just going to add here object and then we got ingredients, we got steps, we got uh time and effort, easy. Not sure where they got it from.


717
01:37:05.985 --> 01:37:12.985
Does this say easy in here anywhere?


718
01:37:12.985 --> 01:37:18.985
No. No. Nope.


719
01:37:18.985 --> 01:37:23.985
Regardless of which… Oh, okay. I guess… Like I said, it's easy.


720
01:37:23.985 --> 01:37:41.985
The information isn't here. Cool. Okay, let me parse this real quick and then I'm just going to Do that. One last thing, because that was a long response So when you do structured outputs in AI SDK, it comes to in the object.


721
01:37:41.985 --> 01:37:47.985
Key. And then now you can save this into a DB pretty easily.


722
01:37:47.985 --> 01:37:52.985
I wish I had more time to do like tool calling, but I'm getting pretty tired right now.


723
01:37:52.985 --> 01:38:06.985
But yeah, structure output, and then you can parse this array, save each one into DB, stuff like that Yeah. I'm going to push this up if you guys need like a


724
01:38:06.985 --> 01:38:19.985
Like…


725
01:38:19.985 --> 01:38:28.985
Should the homework be for this week using tool calling Unstructured outputs in your apps?


726
01:38:28.985 --> 01:38:48.985
I… I feel like we should do our… homework s like I wonder if we should even do homeworks because like you guys are all building your own stuff. Some of you guys are already using this If you haven't used this and this gives you an idea to build something, then yeah, go ahead and do it.


727
01:38:48.985 --> 01:38:54.985
You're really on track to use tools and structure outputs I guess if you have questions, now's the time to ask.


728
01:38:54.985 --> 01:38:59.985
Hmm.


729
01:38:59.985 --> 01:39:00.985
I feel like…


730
01:39:00.985 --> 01:39:09.985
Yeah, it's always about the progress in your project anyway So it doesn't really have to be about the topic.


731
01:39:09.985 --> 01:39:22.985
I feel like every week we would do this week It's kind of a way to like kind of inspire you to like think about use cases to build as opposed to, oh, you have to do this.


732
01:39:22.985 --> 01:39:23.985
Yeah.


733
01:39:23.985 --> 01:39:30.985
Because I kind of wanted you guys to think as like Or you're building a product and instead of like me telling him what to build because like your users are not going to tell you what to build. They'll tell you what they think you should build.


734
01:39:30.985 --> 01:39:39.985
We should always take it with a grain of salt. You should have some sort of like opinion about what you're trying to build and have tastes around what's important.


735
01:39:39.985 --> 01:39:45.985
And then deliver it. Because people will be asking for horses, right? We ask them.


736
01:39:45.985 --> 01:39:51.985
But they want to make cars.


737
01:39:51.985 --> 01:39:56.985
Structured outputs.


738
01:39:56.985 --> 01:40:04.985
I think that French main yeah there we go. So it should be on here now


739
01:40:04.985 --> 01:40:12.985
Boom. Yeah. Yep, that's it for tonight.


740
01:40:12.985 --> 01:40:19.985
We're like, what, four weeks away, including this week?


741
01:40:19.985 --> 01:40:20.985
Oh, I thought it's like a six weeks. Okay. We're three weeks away.


742
01:40:20.985 --> 01:40:24.985
Three weeks.


743
01:40:24.985 --> 01:40:28.985
You guys gotta get on it, you know? If you need anything, let me know. Let Mary know.


744
01:40:28.985 --> 01:40:34.985
We're here for you guys. But I want you guys to cross the finish line. I want you guys to deploy your projects.


745
01:40:34.985 --> 01:40:47.985
I feel super proud about it. Type shit. Well, I mean, this is like recorded, so… I should have said that. But I said that a lot during the hackathon.


746
01:40:47.985 --> 01:40:54.985
That's what you should be talking about, actually. And walking us through your project, that would have been more fun for me at least.


747
01:40:54.985 --> 01:40:57.985
Oh, I mean, if you're sticking around, let me do that right real quick.


748
01:40:57.985 --> 01:40:58.985
Oh my goodness.


749
01:40:58.985 --> 01:41:10.985
Quick, quick 30 seconds overview. What this does is it does Here, let me pull it up. Pmpm dev.


750
01:41:10.985 --> 01:41:24.985
I think it should be learning right now. 2000 perhaps. Yeah, so this is what it looks like. You can drop in like a github url any project. And it should be able to tell you how to rebuild it.


751
01:41:24.985 --> 01:41:32.985
Feature by feature. So let's say we have the, we have this for example I don't know if I can do like nested Yeah.


752
01:41:32.985 --> 01:41:37.985
No, it's short. It's not fun.


753
01:41:37.985 --> 01:41:44.985
What? Oh, it can't do nested.


754
01:41:44.985 --> 01:41:51.985
So let's see if I do click on my GitHub, try to find something Kind of like a script.


755
01:41:51.985 --> 01:41:53.985
Dulenga.


756
01:41:53.985 --> 01:42:00.985
Yeah, I must go right here. Go here, drop the URL in, explore.


757
01:42:00.985 --> 01:42:05.985
So it pulls in basically all the code from that particular repo.


758
01:42:05.985 --> 01:42:10.985
And then, you know, you can check, you see, oh, this is the actual repo. I can read the code from here.


759
01:42:10.985 --> 01:42:23.985
But that's the special part. The special part is in this tab right here. It says features walkthroughs But I'm going to show you this first. So there's this thing called lms.txt which means that This is basically the entire code base that I just pasted in.


760
01:42:23.985 --> 01:42:30.985
But in one long string so that this can be used when I go to cursor, I can paste this whole thing in and start asking questions.


761
01:42:30.985 --> 01:42:35.985
That's cool, but this right here is what I spend most of my time on.


762
01:42:35.985 --> 01:42:43.985
It's called features walkthroughs. So what it's doing right now is it basically looked at this And that it ran.


763
01:42:43.985 --> 01:42:51.985
Gemini 2.0 flash to… kind of like look up all the features that is available in the code base.


764
01:42:51.985 --> 01:43:03.985
And let me show you that real quick. So I use a server function, server action For this, I think it's called… generated features we have.


765
01:43:03.985 --> 01:43:15.985
And then here, what I do is I ran the um I ran the AI SDK generate object function that we just saw earlier.


766
01:43:15.985 --> 01:43:25.985
And then I pass in a schema and then I have a system message and the prompt that says analyze this code base and And here's what the schema looks like.


767
01:43:25.985 --> 01:43:32.985
It's also Zod and it's basically an array. So it's an object first And in that object, there's an array.


768
01:43:32.985 --> 01:43:46.985
Of string. And then I had to give a description So you can give a description inside of a Zot schema so that your AI has a an easier time generating the structure output for you.


769
01:43:46.985 --> 01:43:51.985
Because maybe when I say list of features I need to clarify what do I mean by that, right?


770
01:43:51.985 --> 01:43:57.985
That's why I have a described key here. Pretty straightforward, right? Like it's just a list of strings.


771
01:43:57.985 --> 01:44:09.985
And as you can see, these are the strings. This is string. So web scraping using Playwright, HTML tag structure. These are all the features that were included in the repo.


772
01:44:09.985 --> 01:44:16.985
So as somebody who's completely new to this repo, it's easier for you to look at this and be like, oh, it can do this. It can do that. I can learn that as opposed to like.


773
01:44:16.985 --> 01:44:27.985
All code. Then you got to go and dig in like see like what's doing what So that's the generate features server action And then, yeah.


774
01:44:27.985 --> 01:44:30.985
And then here what I can do is I can click on any of these.


775
01:44:30.985 --> 01:44:40.985
Or I can search for all ones. I can say like scrape or something But maybe I want to do this. I'm going to click on this. Now it's going to run another servo action.


776
01:44:40.985 --> 01:45:01.985
To generate a walk a walkthrough. So this is where I use Gemini 2.0 Pro, I think. And then it was breaking all the time because sometimes the code base is very long The context is very long I have a fallback to OpenAI 03 Mini.


777
01:45:01.985 --> 01:45:09.985
And this is like this huge system message to be like hey like this is the code base. You're supposed to generate blah, blah, blah.


778
01:45:09.985 --> 01:45:25.985
And then that's a system message. And then very important you know preserve all white space indentations so that that looks nice And then I could just like, I just like stuff in the code base content and then the feature to implement, which is literally just the text that we just saw from the list.


779
01:45:25.985 --> 01:45:35.985
So that it knows what we're trying to do. So the model is for flashlight and then I pass in the schema. This is the walkthrough schema.


780
01:45:35.985 --> 01:45:42.985
Which has the file name the full code of the file, which is like, if it's looking at a file, it should return the full code.


781
01:45:42.985 --> 01:45:45.985
The reason why I have this is because this is kind of a hack.


782
01:45:45.985 --> 01:45:50.985
I want to compare the current code to the full code of the file and then highlight it.


783
01:45:50.985 --> 01:46:08.985
What I should have done was parse this from like the initial repo pool and then not make the model do this again because it's just such a waste of And then the current code is like, okay, which code are we talking about at this step?


784
01:46:08.985 --> 01:46:17.985
And then an explanation of the step. So it's almost kind of like a slideshow in a sense. So now it's done. I just had to follow along with this.


785
01:46:17.985 --> 01:46:30.985
You know, you create a new file called scrape.py And then these are the link, I mean, the code for that file and then you click Once you're done with that step, you click on next Now you're going to add these to the script repeal


786
01:46:30.985 --> 01:46:42.985
To your script.py. File and it highlights the stuff that is new. And then there's this like new function down here and then it tells you like why we're doing it.


787
01:46:42.985 --> 01:46:47.985
And then last minute, I had like an audio thing too So like, let's add a function call.


788
01:46:47.985 --> 01:46:54.985
Those like tell you like kind of guide you through it.


789
01:46:54.985 --> 01:46:58.985
And then if I leave it on, it'll actually go to the next stage automatically.


790
01:46:58.985 --> 01:47:11.985
And then see that like it was just scroll to the part that you need to do and it'll tell you like why you're doing it so that as you're coding along, you kind of like know the reason why you're doing certain things?


791
01:47:11.985 --> 01:47:21.985
And then you're going to keep doing that. And then by the end, you would have a working whatever that you're trying to learn.


792
01:47:21.985 --> 01:47:32.985
So nine steps to set up play right. And this is pulled from the code base. So it's uh You're trying to learn a code base, then you can do that.


793
01:47:32.985 --> 01:47:48.985
And then this is the code to generate the code. The walkthrough And then the fallback is obviously OpenAI because Gemini was kind of like finicky. So I have this strict mode here. I use O3 Mini, which is a decent model


794
01:47:48.985 --> 01:47:56.985
And it has a special property called reasoning effort. If it turns to high, it'll take like forever to load. So I had to let low.


795
01:47:56.985 --> 01:48:11.985
And then this is repo mix This is the tricky part because repo mix is actually a CLI tool. So what I had to do was I had to like finesse it so it run in the Vercel serverless function Which is kind of tricky.


796
01:48:11.985 --> 01:48:14.985
This is probably the part I spend the most time on.


797
01:48:14.985 --> 01:48:19.985
To be honest. But


798
01:48:19.985 --> 01:48:20.985
Yeah.


799
01:48:20.985 --> 01:48:27.985
Wait, can I ask a question? So on the generated walkthrough, I'm just curious how you're generating the UI like that.


800
01:48:27.985 --> 01:48:35.985
Oh, the UI. That's the UI stuff. So I have… See?


801
01:48:35.985 --> 01:48:44.985
Because like it generates after you generate the steps and then it just creates the UI components around each step.


802
01:48:44.985 --> 01:48:45.985
Or…


803
01:48:45.985 --> 01:48:53.985
No, this UI is pre-built. I made it so that once the data for the walkthrough is available, then it will display this kind of like walk through editor like this.


804
01:48:53.985 --> 01:49:03.985
Yeah, but like on the left, there's a number of steps, right? So do you define like how many number of like slides you need to do for the UI too?


805
01:49:03.985 --> 01:49:09.985
Oh, no. It would just take however many it wants to generate.


806
01:49:09.985 --> 01:49:14.985
So let's go back here. Go to another one.


807
01:49:14.985 --> 01:49:15.985
Could have been like five steps. I don't have like a specified number of steps for it.


808
01:49:15.985 --> 01:49:21.985
Mm-hmm.


809
01:49:21.985 --> 01:49:30.985
Yeah, that's what I'm asking. How do you get that into the ui I know you can generate like strings for the output, but what about UI components?


810
01:49:30.985 --> 01:49:42.985
So this comes back, like I said, like this is a list of stuff. Let me show you the walkthrough. So this is an object.


811
01:49:42.985 --> 01:49:48.985
Every walkthrough step is an object. That has a file name.


812
01:49:48.985 --> 01:50:04.985
All the code? Some of the code to highlight and then an explanation and then i put that into the actual schema here where it has like a one property called steps And the steps property would just be a list of all these things.


813
01:50:04.985 --> 01:50:13.985
Basically. And then pass that to the generate object server action here.


814
01:50:13.985 --> 01:50:24.985
Where this says schema, something that knows that oh When I input the repo as text i want structure upward out.


815
01:50:24.985 --> 01:50:40.985
As I have declared in the other file. So this is where I get the list of steps. And then once I get the list of steps, I'm going to display that in the walkthrough editor here, which is just react stuff.


816
01:50:40.985 --> 01:50:45.985
Jesus. He has a lot of stuff just to get like the editor working.


817
01:50:45.985 --> 01:50:58.985
As well. Yeah, so once the steps are available Then we're just going to like Do a bunch of stuff here.


818
01:50:58.985 --> 01:51:04.985
I don't remember what I wrote here.


819
01:51:04.985 --> 01:51:06.985
Yeah, it's not like two hours. I honestly don't remember.


820
01:51:06.985 --> 01:51:12.985
Okay, that's like a lot. Yeah, it's a lot of front-end code, apparently. Okay, cool.


821
01:51:12.985 --> 01:51:18.985
Yeah, so also a lot of vibe coding too, as you can tell from like the freaking comments that I never wrote here.


822
01:51:18.985 --> 01:51:32.985
But essentially, there's like a component here and there's a component here And then there's a component here. And then once the steps are available, I'm just going to pass the data down to like this separately, this separately, this separately.


823
01:51:32.985 --> 01:51:38.985
Because every step has like complete context of like which step it is in the array, the content of the file And then the explanation.


824
01:51:38.985 --> 01:51:46.985
Okay. Like in the metadata or something.


825
01:51:46.985 --> 01:51:48.985
Cool. All right.


826
01:51:48.985 --> 01:51:51.985
Yep. This will be in production.


827
01:51:51.985 --> 01:51:54.985
What are the highlights? The highlights, what are they for?


828
01:51:54.985 --> 01:52:02.985
Say that one more time.


829
01:52:02.985 --> 01:52:03.985
The highlights on jello.


830
01:52:03.985 --> 01:52:14.985
The what, sorry? Oh, the highlights for you to know that, hey, this file is pretty long, but this is the two lines that we going to be paying attention to.


831
01:52:14.985 --> 01:52:15.985
Oh, wow.


832
01:52:15.985 --> 01:52:27.985
So it's supposed to be for like one step at a time and the highlighted step, the highlighted coat is the coat that is just supposed to add in a step, but then it's really hard to prompt it to like just write that because as you can see like


833
01:52:27.985 --> 01:52:32.985
From here to here It's supposed to highlight this, honestly.


834
01:52:32.985 --> 01:52:36.985
But then like it's kind of like… screwed up there.


835
01:52:36.985 --> 01:52:37.985
But if you demo it really quick, then people won't see it.


836
01:52:37.985 --> 01:52:42.985
Gotcha. Pretty cool, man.


837
01:52:42.985 --> 01:52:45.985
Yeah, it's a cool project.


838
01:52:45.985 --> 01:52:46.985
Thank you. I'm going to build this out this week.


839
01:52:46.985 --> 01:52:50.985
Awesome. Thank you.


840
01:52:50.985 --> 01:52:56.985
And then put a stripling on it.


841
01:52:56.985 --> 01:53:02.985
Are you going to sell it to us now? Hi. I thought we're building internal tools.


842
01:53:02.985 --> 01:53:06.985
Every time I hit generate, this should cost me money, so…


843
01:53:06.985 --> 01:53:13.985
Oh, that's right. That's right.


844
01:53:13.985 --> 01:53:18.985
Pay for my time. Thank God. It's going to be like $2 a month or something.


845
01:53:18.985 --> 01:53:34.985
I mean, heck, people are going to pay 20 bucks a month If you want. It's a great educational project. But this is relevant for a few of the people too who are working on the GitHub or another learning platform, stuff like that.


846
01:53:34.985 --> 01:53:35.985
Yep. I built this for Gil. Do you know that?


847
01:53:35.985 --> 01:53:40.985
I think Melissa you were building something like this. Why, Gil?


848
01:53:40.985 --> 01:53:41.985
You're the man. You're the man. Because I'm the dumbest student. I need more help. Come on.


849
01:53:41.985 --> 01:53:46.985
You'll ask me about this.


850
01:53:46.985 --> 01:53:54.985
He asked me about it. He's like, I wish there's a tool to explain to me like just the stuff that I need from a code base that i found


851
01:53:54.985 --> 01:53:55.985
That is so cool.


852
01:53:55.985 --> 01:54:03.985
I owe you, man. Any of these signs you need, I'm your man. Actually, I think this would be a really, really cool startup product.


853
01:54:03.985 --> 01:54:16.985
It's going to help a lot of people. I'll drop a few ideas to you that I got while I was using it. Maybe they are helpful but uh this is a really good tool


854
01:54:16.985 --> 01:54:35.985
Please send them my way. I have… Every intention to productionize this because This honestly, when I launched it, had more market pull than like cats with bats. I'm like.


855
01:54:35.985 --> 01:54:36.985
What do you mean by market pool? Like how many people came up to talk to you about this or what?


856
01:54:36.985 --> 01:54:40.985
Man, should I just do this?


857
01:54:40.985 --> 01:54:46.985
Yeah, people will like send me the link ASAP. Need this stuff today.


858
01:54:46.985 --> 01:54:57.985
You know why? Because I told you today too, there's going to be more software engineers thanks to AI now. And they're not going to be like.


859
01:54:57.985 --> 01:54:59.985
Proper, I guess, offenders but like the new generation of


860
01:54:59.985 --> 01:55:03.985
She's talking about you guys, by the way.


861
01:55:03.985 --> 01:55:11.985
Why are you outing like that? No, no. But okay, yeah, why not? For vibe coders, basically.


862
01:55:11.985 --> 01:55:12.985
So we got more tools for vibe coders. Actually.


863
01:55:12.985 --> 01:55:16.985
Yeah, she said it.


864
01:55:16.985 --> 01:55:21.985
Yep. This is basically a live coding tool. It only exists in the vibe coding era.


865
01:55:21.985 --> 01:55:22.985
I love.


866
01:55:22.985 --> 01:55:25.985
It cannot exist anywhere, any other time in history.


867
01:55:25.985 --> 01:55:31.985
Yeah. Oh, my gosh. There's so much to build.


868
01:55:31.985 --> 01:55:34.985
All right.


869
01:55:34.985 --> 01:55:40.985
So before we leave, quick question for you guys. How far are you guys in your project? How do you feel? Do you feel like you're stuck or?


870
01:55:40.985 --> 01:55:43.985
Do okay.


871
01:55:43.985 --> 01:55:49.985
I feel good about my project. I'm in the AI implementation part.


872
01:55:49.985 --> 01:56:03.985
And yeah, it's a lot. Like I drop in one file and test that file and I think it's all good. Then once I add multiple files, it's like debugging hell, but… You know, I'm up to the challenges. It's pretty cool seeing it come together.


873
01:56:03.985 --> 01:56:04.985
Mm-hmm. Real.


874
01:56:04.985 --> 01:56:09.985
But it's a big task. Yeah.


875
01:56:09.985 --> 01:56:12.985
You're crushing it, by the way. Keep going.


876
01:56:12.985 --> 01:56:14.985
Thanks, thanks.


877
01:56:14.985 --> 01:56:24.985
Yeah, I was focusing on the AI part and the UI part up until now. And then last week, I just started on the DB side of things and the auth and everything.


878
01:56:24.985 --> 01:56:29.985
I'm still figuring out the kinks there.


879
01:56:29.985 --> 01:56:38.985
Currently having some issues with how the data is getting parsed into DB, but I think the structured response that we covered today might help.


880
01:56:38.985 --> 01:56:39.985
Put some of that so Thank you.


881
01:56:39.985 --> 01:56:46.985
Yep. Let me know how it goes.


882
01:56:46.985 --> 01:56:47.985
I'm pretty much the same. Okay, go on. Okay.


883
01:56:47.985 --> 01:56:52.985
Yeah, I'm keeping mine, I'm sorry.


884
01:56:52.985 --> 01:57:15.985
I was pretty stuck with trying to get some structured outputs So recipes basically and trying to vectorize it eventually I think it's going to be a huge help like to actually get it out structured and like also filter out a lot of scraping bullshit that I don't really need, but also getting


885
01:57:15.985 --> 01:57:22.985
The best of it, like just the stuff I need. And I think I'm just going to push for all day this week.


886
01:57:22.985 --> 01:57:27.985
Nice. Are you using FyQrawl or what are you using?


887
01:57:27.985 --> 01:57:39.985
Not really firepall, but… I was trying a lot of basic stuff, but I think I'm just going to go on to Beautiful soup, beautiful soupo. Fine, Paul.


888
01:57:39.985 --> 01:57:40.985
I mean, either way just What is it?


889
01:57:40.985 --> 01:57:44.985
I strongly recommend Firefall. I strongly recommend Far Crawl.


890
01:57:44.985 --> 01:57:45.985
Okay.


891
01:57:45.985 --> 01:57:54.985
Park Raw with Markdown. The reason why they have Markdown is because of the use cases like what we saw with structured output and extraction.


892
01:57:54.985 --> 01:58:02.985
Just to make sense of it and getting all the stuff I need. I have like 10 different categories I could textualize.


893
01:58:02.985 --> 01:58:05.985
And there are a few use cases I want to do.


894
01:58:05.985 --> 01:58:25.985
Nice.


895
01:58:25.985 --> 01:58:26.985
Yeah.


896
01:58:26.985 --> 01:58:37.985
Cool, cool. So yeah, I'm just trying to keep the scope really small uh i was at the beginning i was throwing like many files into the data intake process for rag And yeah, kind of like what Melissa was saying, I was just spending a lot of time troubleshooting


897
01:58:37.985 --> 01:58:45.985
The multiple files. So I'm just making a fat single file and using that later I can't prove it.


898
01:58:45.985 --> 01:58:47.985
Yep.


899
01:58:47.985 --> 01:59:06.985
And then I'm trying to figure out how to make the output exactly the stuff that you were talking about today how to get the model to provide that reliable JSON output because if anything changes the DSL doesn't work anymore.


900
01:59:06.985 --> 01:59:11.985
So everything that you were saying today is going to be really useful for me.


901
01:59:11.985 --> 01:59:16.985
And that's where I am. I'm still on the notebook.


902
01:59:16.985 --> 01:59:28.985
So this is like the heavy lifting. Once I'm done with this it's going to be easier to port it into You know, a Python application NetJS or something like that.


903
01:59:28.985 --> 01:59:39.985
I'm still clueless about that. I'm a designer and I'm clueless about the UI. I'm just trying to figure out stuff.


904
01:59:39.985 --> 01:59:40.985
Yeah, man, keep me updated. Seems like you're on the right track.


905
01:59:40.985 --> 01:59:50.985
First but it's fun. I'm really excited.


906
01:59:50.985 --> 02:00:00.985
My AI response actually takes a lot of time. I'm not sure if that's normal like it takes like two three minutes for the air response too.


907
02:00:00.985 --> 02:00:02.985
Not normal.


908
02:00:02.985 --> 02:00:07.985
That's not normal, right? Never seen something wrong.


909
02:00:07.985 --> 02:00:12.985
Well, I guess it depends. Are you using like 01 Pro or something


910
02:00:12.985 --> 02:00:17.985
No, I'm using the AI SDK.


911
02:00:17.985 --> 02:00:24.985
4. Gpt-4, I think.


912
02:00:24.985 --> 02:00:25.985
Yeah, at least. Yeah, yeah.


913
02:00:25.985 --> 02:00:40.985
No. So without… seeing the code or looking at the logs. If you want to like add some tracing to your code. So like add some logging to like the result and what happens before the result maybe we can take a look at that together at some point over chat.


914
02:00:40.985 --> 02:00:45.985
Yeah.


915
02:00:45.985 --> 02:00:50.985
Yeah, will it happen if my prompt just Too big?


916
02:00:50.985 --> 02:00:51.985
How big are you talking?


917
02:00:51.985 --> 02:00:58.985
I mean, not that big. I mean, it's… I don't know how to explain how big it could be It's… No, no, no, no. It's not that big at all. It's like a page, maybe.


918
02:00:58.985 --> 02:01:06.985
It shouldn't matter because I passed like a whole… repo into my Yeah.


919
02:01:06.985 --> 02:01:07.985
Yeah. Okay.


920
02:01:07.985 --> 02:01:14.985
Yeah. So when you say like, yeah, maybe like lock some stuff out into the console.


921
02:01:14.985 --> 02:01:15.985
Right.


922
02:01:15.985 --> 02:01:21.985
Because when you… AI responds slow. Do you mean like when it shows up on the screen or when it's like actually done Oh, thinking state.


923
02:01:21.985 --> 02:01:27.985
It's like in the loading state, in the thinking state


924
02:01:27.985 --> 02:01:28.985
This is not a thinking model, right? But you just have a thinking


925
02:01:28.985 --> 02:01:38.985
Like you it's not, it's not. And it's just loading. Like when it's just um Then you submit and then you submit before it pops up into your screen. It ticks.


926
02:01:38.985 --> 02:01:40.985
Two to three minutes. I mean, not three, two and a half Two minutes for sure.


927
02:01:40.985 --> 02:01:42.985
Two to three minutes.


928
02:01:42.985 --> 02:01:46.985
What is your stack? What are you using?


929
02:01:46.985 --> 02:01:49.985
Next.js TypeScript. Yeah, I'm thinking I should, yeah, like I said, add some traceability there.


930
02:01:49.985 --> 02:01:55.985
Okay.


931
02:01:55.985 --> 02:02:01.985
Because, yeah. Because I don't think that's normal.


932
02:02:01.985 --> 02:02:02.985
Mm-hmm.


933
02:02:02.985 --> 02:02:09.985
Maybe at some times for the before and after to see if it improves once you do stuff and maybe it goes down to 90 seconds, maybe it goes down to 60 but eventually


934
02:02:09.985 --> 02:02:10.985
Yeah.


935
02:02:10.985 --> 02:02:19.985
Yeah, actually, you should sign up for Langsmith. And then just add it to your code base.


936
02:02:19.985 --> 02:02:20.985
Okay.


937
02:02:20.985 --> 02:02:26.985
It's really simple. It's like one line of code. And then you have like open AI tracing. And you can see how long each call to OpenAI will take.


938
02:02:26.985 --> 02:02:27.985
Okay. Thank you.


939
02:02:27.985 --> 02:02:34.985
Under the latency. And it's free for like one million traces or something like that. So it should be free for a long time.


940
02:02:34.985 --> 02:02:36.985
That's good. Yeah.


941
02:02:36.985 --> 02:02:43.985
Yeah. Yeah. So once you sign up, I strongly recommend set up setting up Langsmith. And then… Show me the traces and then we'll see. We'll take it from there.


942
02:02:43.985 --> 02:02:50.985
Okay. Thank you.


943
02:02:50.985 --> 02:03:05.985
Yep.


944
02:03:05.985 --> 02:03:11.985
Come on, people, don't be shy.


945
02:03:11.985 --> 02:03:24.985
My project is going well. I'm implementing the part where you can like where you can kind of have a coding agent for my HTML, CSS code editor.


946
02:03:24.985 --> 02:03:27.985
And I'm starting that process now. But everything's looking good.


947
02:03:27.985 --> 02:03:31.985
Nice.


948
02:03:31.985 --> 02:03:34.985
If I have questions, I will let you know.


949
02:03:34.985 --> 02:03:45.985
Awesome, man. Love to hear it.


950
02:03:45.985 --> 02:04:07.985
About my progress up until Friday now. So I was able to scrape. So I'm working on something like very similar to what Kelsey is doing but in different domain and like it's it's not very domain specific It's like you would search any length of topics on the research


951
02:04:07.985 --> 02:04:14.985
And then the AI part would summarize the research for you rerank it and basically after summaries it would give you a research direction.


952
02:04:14.985 --> 02:04:20.985
Mm-hmm.


953
02:04:20.985 --> 02:04:24.985
For example, if you say that I want to research on X topic.


954
02:04:24.985 --> 02:04:37.985
And existing research and the next topic it would take the delta and suggest you What's the resource direction exactly? How should you work on and what should we focus on after summarizing the papers that exist in the space?


955
02:04:37.985 --> 02:04:52.985
So I am pretty much able to find out all the papers like through different APIs.


956
02:04:52.985 --> 02:04:53.985
Mm-hmm.


957
02:04:53.985 --> 02:05:03.985
Like not just a semantic scholar, but like PubMed ai generated also trying to use fire crawl, like you suggested And then… It's going pretty smooth and the relevancy is also going pretty smooth like up until Friday, I could get top 10 papers, which I'm going to squeeze down top five


958
02:05:03.985 --> 02:05:04.985
Mm-hmm.


959
02:05:04.985 --> 02:05:13.985
And then the summary part that's not working. So I'm fixing that because all of the time I was just wipe coding. Basically, I'm new to TypeScript.


960
02:05:13.985 --> 02:05:14.985
So I'm a little embarrassed like i did not even…


961
02:05:14.985 --> 02:05:21.985
We're clipping that. We're clipping that on LinkedIn.


962
02:05:21.985 --> 02:05:22.985
I just been vibe coding.


963
02:05:22.985 --> 02:05:40.985
So basically doing types. Yeah, TypeScripting, I started using TypeScript and learning more of it and trying to debug where I'm failing for the research summary Sorry, now I'm stuck. But the relevancy part is really good like it's throwing Yeah.


964
02:05:40.985 --> 02:05:43.985
Nice, nice. That's awesome. How do you do your re-ranking?


965
02:05:43.985 --> 02:05:46.985
That was an aha moment for me. What was that? Sorry.


966
02:05:46.985 --> 02:05:48.985
How do you do your re-ranking?


967
02:05:48.985 --> 02:06:08.985
So I just use Claude and chat GPT for a model like 3.5 sorry And use that formulae. That's the basic formulae that it grows like just a mathematical formula like How is it calculating the context window or sorry the tokens of all the


968
02:06:08.985 --> 02:06:09.985
Embeddings and then it gives you the highest score.


969
02:06:09.985 --> 02:06:22.985
Mm-hmm.


970
02:06:22.985 --> 02:06:23.985
Interesting.


971
02:06:23.985 --> 02:06:28.985
Like in percent wise 100%, 78 blah blah and then I'm just getting the numbers based on these models right now. So of course, Claude was expensive. So I'm just focusing on GPT and some free models.


972
02:06:28.985 --> 02:06:29.985
Mm-hmm.


973
02:06:29.985 --> 02:06:41.985
And I'm still trying to fine tune and sorry, still trying to optimize on that part so But that was a good learning for me like how is it using the relevancy on the topic.


974
02:06:41.985 --> 02:06:42.985
Yeah, that's interesting how we do ranking like that. It's cool. If it works, it works.


975
02:06:42.985 --> 02:06:46.985
So.


976
02:06:46.985 --> 02:06:54.985
I'm not using vector db and all of that. I was just trying to get paper IDs into super base right now.


977
02:06:54.985 --> 02:06:55.985
Mm-hmm.


978
02:06:55.985 --> 02:07:06.985
Not created my login page also because I just focused on getting, you know, working UI and uh If I'm actually able to call the APIs, et cetera, from different sources.


979
02:07:06.985 --> 02:07:24.985
I'll try to use tool calling for the cross-referencing of multiple sources like being very specific for specific domain. If I need scientific papers, just go through this. And if you need any other technology papers go through other api etc so


980
02:07:24.985 --> 02:07:26.985
Let's see how does that work in my case.


981
02:07:26.985 --> 02:07:36.985
Cool. I'm excited to see it.


982
02:07:36.985 --> 02:07:40.985
Is Tess here? Tess!


983
02:07:40.985 --> 02:07:50.985
Tess. I don't think Tess is here anymore. Frederick.


984
02:07:50.985 --> 02:07:51.985
Patrick.


985
02:07:51.985 --> 02:07:58.985
Yeah, I do have questions, but you said you were tired about 30 minutes ago, so I don't want to delay you. So I'll save it.


986
02:07:58.985 --> 02:08:00.985
Go for it, man. Go for it.


987
02:08:00.985 --> 02:08:27.985
Well, okay, fine. So basically, I'm working with two models right now. I have one LLM for my companion model and I have another LLM for my agent. So what I'm doing is that I'm piping the output of my agent after they finish their tool calling back to the main companion model.


988
02:08:27.985 --> 02:08:54.985
Now, when I test these models individually, they seem to work pretty well. But when I combine something weird is happening Like, I don't know what Landgraph is doing, but there's some sort of threading issue because my main function, like the function that's supposed to only run once when you run streamlet, run the APP.py


989
02:08:54.985 --> 02:09:01.985
It gets cold again and again and again and again. So there's some sort of threading that's going on that I'm not doing.


990
02:09:01.985 --> 02:09:11.985
That's going on in the background but um But I guess the other thing is that the model I'm using for the agent tool calling, which is Quinn.


991
02:09:11.985 --> 02:09:20.985
It's being very stochastic. Even though when I set the temperature to zero, it's still like sometimes it calls the tools and other times it won't.


992
02:09:20.985 --> 02:09:34.985
Even though the input's the same. So I'm going to try that thing. I'm going to like a rename the function, like the tool functions. I'm gonna uh like adjust the system prompt.


993
02:09:34.985 --> 02:09:35.985
And I'm also going to… Oh.


994
02:09:35.985 --> 02:09:39.985
You might need to do some few shot there because… For smaller models like Gwen's models, few shotting usually helps.


995
02:09:39.985 --> 02:09:44.985
Okay. All right. All right. I will keep that in mind. But yeah, yeah. So I'll see what progress I make by Wednesday. And if not, I'll reach out to you again.


996
02:09:44.985 --> 02:09:50.985
Yep.


997
02:09:50.985 --> 02:09:51.985
Office hours. Thanks.


998
02:09:51.985 --> 02:10:03.985
Yeah. And there are two ways to do few shouting too. You can do few shouting in the system message. So like just literally say like, here are some examples or you can insert fake messages into your message history that's like my go-to


999
02:10:03.985 --> 02:10:04.985
So like, yeah.


1000
02:10:04.985 --> 02:10:12.985
Oh. Oh, okay. So insert synthetic messages into the history itself Okay. Interesting.


1001
02:10:12.985 --> 02:10:20.985
Yeah. Just be like… From my experience, that has been a better performing way to do it.


1002
02:10:20.985 --> 02:10:28.985
So if you have a two call message See, you would have like a fake question and then you have like the right tool call after that.


1003
02:10:28.985 --> 02:10:31.985
From the assistant. And then just keep doing that for all the tools.


1004
02:10:31.985 --> 02:10:39.985
A couple of times. And then somehow that's like super clear for the model to know like oh i should Do this when this happens.


1005
02:10:39.985 --> 02:10:45.985
Huh. Okay. All right. So something to think about. Okay. Thanks. Thanks a lot.


1006
02:10:45.985 --> 02:10:51.985
And for the first question, I honestly don't know. Maybe if we can look at the code together or something, but… Is your agent running like async or sync?


1007
02:10:51.985 --> 02:11:11.985
Okay. No, I'm not doing Tom. Maybe I should look into async, but right now I'm not like, I'm not labeling any of my functions as async because I was not expecting multi-threading but because It's being called sequentially. It's not like two models running at the same time it's like


1008
02:11:11.985 --> 02:11:33.985
First, the agent gives the user query. It runs the tool calls like it needs, and then it pipes the output back into the main model. So it's supposed to be done sequentially so I didn't I didn't think the knee, like I needed async


1009
02:11:33.985 --> 02:11:39.985
But yeah, we'll see. Maybe it's not that big of a deal, but we'll see.


1010
02:11:39.985 --> 02:11:40.985
Like, oh.


1011
02:11:40.985 --> 02:11:54.985
Oh, let me ask you something. Are you doing hands-off like through code or like regular code or are you doing it through like gland graphs api because land graph has like a like a node thing that can pass on to another agent.


1012
02:11:54.985 --> 02:12:13.985
But it has to be like a line graph like method it's supposed to like regular code.


1013
02:12:13.985 --> 02:12:14.985
Yep.


1014
02:12:14.985 --> 02:12:23.985
I might be doing it through, I'm definitely calling a certain language. I'm building the uh like uh i'm building the graph uh for for the agent routing protocol like uh And then the result of that, I'm calling the stream method. So that might be it.


1015
02:12:23.985 --> 02:12:36.985
Okay, but… But yeah, like it's not necessarily problematic. Like the output's still going on. It's just weird because I'm not I'm not supposed to be doing multi-threading. It's not something I'm doing on purpose so We'll see. We'll see.


1016
02:12:36.985 --> 02:12:41.985
Mm-hmm.


1017
02:12:41.985 --> 02:12:49.985
Okay, but yeah, you know, I'll definitely take your advice into consideration


1018
02:12:49.985 --> 02:12:56.985
Yeah, interesting problem. I would be curious to see what you find.


1019
02:12:56.985 --> 02:13:06.985
Cool. All right, guys. That's it for the stream today. Tune in tomorrow at 1 p.m. Est to see me uh build couch test.


1020
02:13:06.985 --> 02:13:08.985
Awesome. See you guys.


1021
02:13:08.985 --> 02:13:10.985
Awesome. Thank you so much.


1022
02:13:10.985 --> 02:13:15.825
Good night, hon.



